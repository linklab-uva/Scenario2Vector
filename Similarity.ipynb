{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate Similarities\n",
    "\n",
    "The following code calculates the similarity between every pair of phrases using Sent2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the sent2vec embeddings from file\n",
    "import numpy as np\n",
    "\n",
    "def read_embeddings(embeddings_path):\n",
    "    \"\"\"Arguments:\n",
    "        - embeddings_path: path to the embeddings\n",
    "    \"\"\"\n",
    "    with open(embeddings_path, 'r') as in_stream:\n",
    "        embeddings = []\n",
    "        for line in in_stream:\n",
    "            line = '['+line.replace(' ',',')+']'\n",
    "            embeddings.append(eval(line))\n",
    "        return embeddings\n",
    "    return []\n",
    "\n",
    "embeddings = np.array(read_embeddings(\"./bddx_embeddings.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dist(e1,e2):\n",
    "    return np.linalg.norm(e1-e2) # Euclidean Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26539\n"
     ]
    }
   ],
   "source": [
    "print(embeddings.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the similarity between every pair of phrases\n",
    "matrix_size = embeddings.shape[0]\n",
    "dist_matrix = np.zeros((matrix_size,matrix_size))\n",
    "\n",
    "for i in range(matrix_size):\n",
    "    dist_matrix[i][i] = 0.0\n",
    "    if i%1000 == 0:\n",
    "        print(i) # Lets the user track progress\n",
    "    for j in range(i+1,matrix_size):\n",
    "        d = dist(embeddings[i],embeddings[j])\n",
    "        dist_matrix[i][j] = d\n",
    "        dist_matrix[j][i] = d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the distance matrix to file. Since the matrix is very large, we split it across\n",
    "# multiple files\n",
    "def save_to_file(matrix,filename,page_size=1000):\n",
    "    import pickle as pkl\n",
    "    from math import ceil\n",
    "\n",
    "    path = \"/Volumes/External HD/Deep Learning\"\n",
    "    for i in range(ceil(matrix.shape[0]/page_size)):\n",
    "        print(\"%i / %i\"%(i,matrix.shape[0]/page_size))\n",
    "        with open(\"%s/%s_%i.pkl\"%(path,filename,i),\"wb\") as _output:\n",
    "            if i == ceil(matrix.shape[0]/page_size):\n",
    "                pkl.dump(matrix[i*page_size:],_output)\n",
    "            else:\n",
    "                pkl.dump(matrix[i*page_size:(i+1)*page_size],_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_to_file(dist_matrix,\"sent2vec_dist\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform Similarity Tests\n",
    "\n",
    "The following code looks at the results of the calculated similarities.\n",
    "\n",
    "WARNING: High memory required to open both matrices simultaneously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the distance matrix from file. Skip this step if you still have the distance matrix from\n",
    "# the above calculations\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "from math import ceil\n",
    "\n",
    "def load_from_file(filename,page_size=1000):\n",
    "    path = \"/Volumes/External HD/Deep Learning\"\n",
    "\n",
    "    with open(\"%s/%s_%i.pkl\"%(path,filename,0),\"rb\") as _init_in:\n",
    "        init_matrix = pkl.load(_init_in)\n",
    "\n",
    "    page_size = init_matrix.shape[0]\n",
    "    matrix_size = init_matrix.shape[1]\n",
    "\n",
    "    output = np.zeros((matrix_size,matrix_size))\n",
    "    output[0:page_size] = init_matrix\n",
    "\n",
    "    for i in range(1,ceil(matrix_size/page_size)):\n",
    "        with open(\"%s/%s_%i.pkl\"%(path,filename,i),\"rb\") as _init_in:\n",
    "            init_matrix = pkl.load(_init_in)\n",
    "        output[i*page_size:(i+1)*page_size] = init_matrix\n",
    "\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.4841733350580784\n"
     ]
    }
   ],
   "source": [
    "dist_matrix = load_from_file(\"sent2vec_dist\")\n",
    "print(dist_matrix[-1,-2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "sdl_matrix = load_from_file(\"sdl_dist\")\n",
    "print(sdl_matrix[-1,-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7566601926122294\n"
     ]
    }
   ],
   "source": [
    "#d_avg = np.average(dist_matrix)\n",
    "d_std = np.std(dist_matrix)\n",
    "\n",
    "dist_matrix = dist_matrix/d_std\n",
    "\n",
    "#print(d_avg)\n",
    "print(d_std)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4707403197629428\n"
     ]
    }
   ],
   "source": [
    "#s_avg = np.average(sdl_matrix)\n",
    "s_std = np.std(sdl_matrix)\n",
    "\n",
    "sdl_matrix = sdl_matrix/s_std\n",
    "\n",
    "#print(s_avg)\n",
    "print(s_std)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_matrix-=sdl_matrix\n",
    "\n",
    "# delete sdl_matrix to save on memory overhead\n",
    "sdl_matrix = None\n",
    "del sdl_matrix\n",
    "\n",
    "dist_matrix = np.absolute(dist_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 / 26\n",
      "1 / 26\n",
      "2 / 26\n",
      "3 / 26\n",
      "4 / 26\n",
      "5 / 26\n",
      "6 / 26\n",
      "7 / 26\n",
      "8 / 26\n",
      "9 / 26\n",
      "10 / 26\n",
      "11 / 26\n",
      "12 / 26\n",
      "13 / 26\n",
      "14 / 26\n",
      "15 / 26\n",
      "16 / 26\n",
      "17 / 26\n",
      "18 / 26\n",
      "19 / 26\n",
      "20 / 26\n",
      "21 / 26\n",
      "22 / 26\n",
      "23 / 26\n",
      "24 / 26\n",
      "25 / 26\n",
      "26 / 26\n"
     ]
    }
   ],
   "source": [
    "save_to_file(dist_matrix,\"diff\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4803602957450845\n"
     ]
    }
   ],
   "source": [
    "dist_matrix = load_from_file(\"diff\")\n",
    "\n",
    "print(dist_matrix[-1][-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7851664212355964\n",
      "1.3568757958621107\n"
     ]
    }
   ],
   "source": [
    "avg = np.average(dist_matrix)\n",
    "std = np.std(dist_matrix)\n",
    "\n",
    "print(avg)\n",
    "print(std)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65267\n",
      "735795\n"
     ]
    }
   ],
   "source": [
    "similar = []\n",
    "not_similar = []\n",
    "\n",
    "sim_val      = 0.005\n",
    "sim_ignore   = 0.0001\n",
    "unsim_val    = 5.45\n",
    "unsim_ignore = 5.50\n",
    "\n",
    "for i in range(dist_matrix.shape[0]):\n",
    "    for j in range(i+1,dist_matrix.shape[1]):\n",
    "        if dist_matrix[i][j] < sim_val and dist_matrix[i][j] > sim_ignore:\n",
    "            similar.append((i,j))\n",
    "        elif dist_matrix[i][j] > unsim_val and dist_matrix[i][j] < unsim_ignore:\n",
    "            not_similar.append((i,j))\n",
    "\n",
    "print(len(similar))\n",
    "print(len(not_similar))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 14642)\n",
      "(1, 4588)\n",
      "(1, 9011)\n",
      "(1, 10390)\n",
      "(2, 25014)\n",
      "(5, 14833)\n",
      "(5, 23282)\n",
      "(6, 10992)\n",
      "(7, 810)\n",
      "(7, 1400)\n",
      "(7, 2752)\n",
      "(7, 4227)\n",
      "(7, 8395)\n",
      "(7, 8852)\n",
      "(7, 9065)\n",
      "(7, 9558)\n",
      "(7, 11504)\n",
      "(7, 16965)\n",
      "(7, 18581)\n",
      "(7, 21277)\n",
      "(7, 21378)\n",
      "(7, 24561)\n",
      "\n",
      "(0, 2632)\n",
      "(0, 4420)\n",
      "(0, 5583)\n",
      "(0, 5606)\n",
      "(0, 6503)\n",
      "(0, 9542)\n",
      "(0, 10978)\n",
      "(0, 11197)\n",
      "(0, 11890)\n",
      "(0, 14553)\n",
      "(0, 15323)\n",
      "(0, 16068)\n",
      "(0, 17037)\n",
      "(0, 17364)\n",
      "(0, 18451)\n",
      "(0, 22149)\n",
      "(0, 22369)\n",
      "(0, 22602)\n",
      "(0, 22696)\n",
      "(0, 22793)\n",
      "(0, 23105)\n",
      "(0, 24275)\n",
      "(0, 25103)\n",
      "(0, 25266)\n"
     ]
    }
   ],
   "source": [
    "for sim in similar:\n",
    "    if sim[0] > 7:\n",
    "        break\n",
    "    print(sim)\n",
    "    \n",
    "print()\n",
    "for not_sim in not_similar:\n",
    "    if not_sim[0] > 0:\n",
    "        break\n",
    "    print(not_sim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3261\n",
      "5365\n",
      "6412\n",
      "7555\n",
      "8845\n",
      "9742\n",
      "10293\n",
      "10607\n",
      "11016\n",
      "11855\n",
      "12860\n",
      "13334\n",
      "13868\n",
      "14312\n",
      "14358\n",
      "14821\n",
      "14869\n",
      "15262\n",
      "16107\n",
      "16743\n",
      "19288\n",
      "20886\n",
      "20916\n",
      "21459\n",
      "23528\n",
      "23540\n",
      "24429\n",
      "24944\n",
      "25909\n"
     ]
    }
   ],
   "source": [
    "for n in not_similar:\n",
    "    if n[0] == 1592:\n",
    "        print(n[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"sim.pkl\",\"wb\") as _output:\n",
    "    pkl.dump(similar,_output)\n",
    "\n",
    "with open(\"not_sim.pkl\",\"wb\") as _output:\n",
    "    pkl.dump(not_similar,_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similar = []\n",
    "not_similar = []\n",
    "\n",
    "with open(\"sim.pkl\",\"rb\") as _in:\n",
    "    similar = pkl.load(,_in)\n",
    "\n",
    "with open(\"not_sim.pkl\",\"rb\") as _in:\n",
    "    not_similar = pkl.load(_in)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The car stops because it turns to the right.\n",
      "The car stops bec\n",
      "The car accelerates slowly to a maintained speed because the light has turned green and traffic is flowing smoothly.\n",
      "Driver removes camera Driver removes camera\n",
      "The car accelerates slowly to a maintained speed because the light has turned green and traffic is flowing smoothly.\n",
      "Driver removes camera Driver removes camera\n",
      "The car is driving forward as traffic flows freely.\n",
      "Driver removes camera Driver removes camera\n",
      "The car is driving forward as traffic flows freely.\n",
      "Driver removes camera Driver removes camera\n",
      "The car merges into the lane to its left to get around a slower car in front of it.\n",
      "Driver removes camera Driver removes camera\n",
      "The car merges into the lane to its left to get around a slower car in front of it.\n",
      "Driver removes camera Driver removes camera\n",
      "The car drives at a normal speed as traffic moves freely.\n",
      "[Camera is blocked] [Camera is blocked]\n",
      "The car drives at a normal speed as traffic moves freely.\n",
      "Driver takes camera down off dashboard. Driver takes camera down off dashboard.\n",
      "The car drives at a normal speed as traffic moves freely.\n",
      "The camera is removed The camera is removed\n",
      "The car drives at a normal speed as traffic moves freely.\n",
      "The camera is removed The camera is removed\n"
     ]
    }
   ],
   "source": [
    "sanity_check = []\n",
    "check_sim = False\n",
    "\n",
    "if check_sim:\n",
    "    for sim in similar:\n",
    "        if sim[0] > 7:\n",
    "            break\n",
    "        sanity_check.append(sim)\n",
    "        print(phrase_lookup[sim[0]])\n",
    "        print(phrase_lookup[sim[1]])\n",
    "        print()\n",
    "else:\n",
    "    for not_sim in not_similar:\n",
    "        if not_sim[0] > 10:\n",
    "            break\n",
    "        sanity_check.append(not_sim)\n",
    "        print(phrase_lookup[not_sim[0]])\n",
    "        print(phrase_lookup[not_sim[1]])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "437124287\n",
      "(26539, 26539)\n"
     ]
    }
   ],
   "source": [
    "print(np.count_nonzero(dist_matrix <= 2.0))\n",
    "print(np.count_nonzero(dist_matrix <= 3.0))\n",
    "print(dist_matrix.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phrase Lookup\n",
    "This code loads the phrases and arranges them such that the phrases align with the indices of the previous methods (e.g., phrase_lookup\\[0\\] refers to the phrase associated with dist_matrix\\[0\\])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read phrases from file to be able to manually examine their similarity\n",
    "import pandas as pd # Pandas library enables data manipulation\n",
    "data_url = \"./revisedBDDX.csv\"\n",
    "def load_bddx_data(csv_name):\n",
    "    column_names = ['Index', 'InputVideo', '1S', '1E', '1A', '1J', '2S', '2E', '2A', '2J', '3S', '3E', '3A', '3J',\n",
    "                    '4S', '4E', '4A', '4J','5S', '5E', '5A', '5J','6S', '6E', '6A', '6J','7S', '7E', '7A', '7J',\n",
    "                    '8S', '8E', '8A', '8J','9S', '9E', '9A', '9J','10S', '10E', '10A', '10J','11S', '11E', '11A', '11J',\n",
    "                    '12S', '12E', '12A', '12J','13S', '13E', '13A', '13J','14S', '14E', '14A', '14J','15S', '15E', '15A', '15J']\n",
    "    \n",
    "    return pd.read_csv(csv_name, names=column_names)\n",
    "\n",
    "bddx = load_bddx_data(data_url)\n",
    "bddx = bddx.drop(['1S', '1E','2S', '2E','3S', '3E','4S', '4E','5S', '5E','6S', '6E','7S', '7E','8S', '8E','9S', '9E','10S', '10E','11S', '11E','12S', '12E','13S', '13E','14S', '14E','15S', '15E', ], axis=1)\n",
    "bddx = bddx.fillna(\"\")\n",
    "\n",
    "bddx['1AJ'] = bddx[['1A', '1J']].agg(' '.join, axis=1)\n",
    "bddx['2AJ'] = bddx[['2A', '2J']].agg(' '.join, axis=1)\n",
    "bddx['3AJ'] = bddx[['3A', '3J']].agg(' '.join, axis=1)\n",
    "bddx['4AJ'] = bddx[['4A', '4J']].agg(' '.join, axis=1)\n",
    "bddx['5AJ'] = bddx[['5A', '5J']].agg(' '.join, axis=1)\n",
    "bddx['6AJ'] = bddx[['6A', '6J']].agg(' '.join, axis=1)\n",
    "bddx['7AJ'] = bddx[['7A', '7J']].agg(' '.join, axis=1)\n",
    "bddx['8AJ'] = bddx[['8A', '8J']].agg(' '.join, axis=1)\n",
    "bddx['9AJ'] = bddx[['9A', '9J']].agg(' '.join, axis=1)\n",
    "bddx['10AJ'] = bddx[['10A', '10J']].agg(' '.join, axis=1)\n",
    "bddx['11AJ'] = bddx[['11A', '11J']].agg(' '.join, axis=1)\n",
    "bddx['12AJ'] = bddx[['12A', '12J']].agg(' '.join, axis=1)\n",
    "bddx['13AJ'] = bddx[['13A', '13J']].agg(' '.join, axis=1)\n",
    "bddx['14AJ'] = bddx[['14A', '14J']].agg(' '.join, axis=1)\n",
    "bddx['15AJ'] = bddx[['15A', '15J']].agg(' '.join, axis=1)\n",
    "\n",
    "bddx = bddx.drop(['Index', '1A', '1J', '2A', '2J', '3A', '3J', '4A', '4J', '5A', '5J', '6A', '6J', '7A', '7J', '8A', '8J', '9A', '9J', '10A', '10J', '11A', '11J', '12A', '12J', '13A', '13J', '14A', '14J', '15A', '15J', ], axis=1)\n",
    "bddx = bddx.drop(bddx.index[0])\n",
    "\n",
    "sdlList = []\n",
    "for index, row in bddx.iterrows():\n",
    "    sdlList.append(row.astype(str))\n",
    "    \n",
    "sdlStatements = []\n",
    "for i in range(len(sdlList)):\n",
    "    sdlStatements.append({'1': sdlList[i]['1AJ'], '2': sdlList[i]['2AJ'], '3': sdlList[i]['3AJ'], '4': sdlList[i]['4AJ'], \n",
    "                        '5': sdlList[i]['5AJ'], '6': sdlList[i]['6AJ'], '7': sdlList[i]['7AJ'], '8': sdlList[i]['8AJ'], \n",
    "                        '9': sdlList[i]['9AJ'], '10': sdlList[i]['10AJ'], '11': sdlList[i]['11AJ'], '12': sdlList[i]['12AJ'], \n",
    "                        '13': sdlList[i]['13AJ'], '14': sdlList[i]['14AJ'], '15': sdlList[i]['15AJ']})\n",
    "\n",
    "phrase_lookup = []\n",
    "\n",
    "for i in range(len(sdlStatements)):\n",
    "    keysTemp = list(sdlStatements[i].keys())\n",
    "    for j in keysTemp:\n",
    "        if (sdlStatements[i][j]==\" \"):\n",
    "            continue\n",
    "        else:\n",
    "            phrase_lookup.append(sdlStatements[i][j])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SDL Ranking Consistency\n",
    "Checks whether the rankings are consistent between S2V and SDL embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "22000\n",
      "23000\n",
      "24000\n",
      "25000\n",
      "26000\n"
     ]
    }
   ],
   "source": [
    "matrix_size = sdl_matrix.shape[0]\n",
    "output = []\n",
    "mask = 9999\n",
    "\n",
    "for i in range(matrix_size):\n",
    "    if i%1000 == 0:\n",
    "        print(i)\n",
    "    temp = sdl_matrix[i][i] # = 0.0\n",
    "    sdl_matrix[i][i] = mask # ignore self\n",
    "    output.append(np.where(sdl_matrix[i] == sdl_matrix[i].min())[0].tolist())\n",
    "    sdl_matrix[i][i] = temp # ignore self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "\n",
    "with open(\"sdl_rank.pkl\",\"wb\") as _out:\n",
    "    pkl.dump(output,_out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n"
     ]
    }
   ],
   "source": [
    "matrix_size = dist_matrix.shape[0]\n",
    "output = []\n",
    "mask = 9999\n",
    "mismatch = 0\n",
    "\n",
    "for i in range(matrix_size):\n",
    "    if i%1000 == 0:\n",
    "        print(i)\n",
    "    temp = [(i,dist_matrix[i][i])]\n",
    "    dist_matrix[i][i] = mask # ignore self\n",
    "    indices = np.argsort(dist_matrix[i])\n",
    "    cutoff = len(sdl[i])-1\n",
    "    dist_matrix[i][indices[cutoff]] == dist_matrix[i][indices[cutoff+1]]\n",
    "    if dist_matrix[i][indices[cutoff]] == dist_matrix[i][indices[cutoff+1]]:\n",
    "        mismatch+=1 # Count the number of mismatches for bookkeeping purposes\n",
    "    while dist_matrix[i][indices[cutoff]] == dist_matrix[i][indices[cutoff+1]] and cutoff > 0:\n",
    "        cutoff-=1\n",
    "    output.append(indices[0:cutoff+1].tolist())\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "\n",
    "with open(\"s2v_rank.pkl\",\"wb\") as _out:\n",
    "    pkl.dump(output,_out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "\n",
    "with open(\"sdl_rank.pkl\",\"rb\") as _in:\n",
    "    sdl = pkl.load(_in)\n",
    "\n",
    "with open(\"s2v_rank.pkl\",\"rb\") as _in:\n",
    "    s2v = pkl.load(_in)\n",
    "    \n",
    "if len(sdl) != len(s2v):\n",
    "    print(\"Warning: list lengths do not match\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "22000\n",
      "23000\n",
      "24000\n",
      "25000\n",
      "26000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "output = []\n",
    "# The format of output will be\n",
    "#   (TP, FP, FN)\n",
    "\n",
    "\n",
    "for i in range(len(s2v)):\n",
    "    if i%1000 == 0:\n",
    "        print(i)\n",
    "    tp = 0\n",
    "    fp = 0\n",
    "    fn = 0\n",
    "    gt = set(s2v[i]) # samples of interest\n",
    "    pred = set(sdl[i])\n",
    "    n = gt.intersection(pred)\n",
    "    tp = len(n)\n",
    "    fp = len(pred-n)\n",
    "    fn = len(gt-n)\n",
    "    output.append((tp,fp,fn))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open(\"rank_analysis.pkl\",\"wb\") as _out:\n",
    "    pkl.dump(output,_out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open(\"rank_analysis.pkl\",\"rb\") as _in:\n",
    "    analysis = pkl.load(_in)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = []\n",
    "\n",
    "for i in range(len(analysis)):\n",
    "    tp,fp,fn = analysis[i]\n",
    "    if tp == 0 and (fp == 0 or fn == 0):\n",
    "        print(i)\n",
    "        print(analysis[i])\n",
    "    p = tp/(tp+fp)\n",
    "    r = tp/(tp+fn)\n",
    "    if tp == 0:\n",
    "        f1.append(0)\n",
    "    else:\n",
    "        f1.append(2*(p*r)/(p+r))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "j = []\n",
    "\n",
    "for i in range(len(analysis)):\n",
    "    tp,fp,fn = analysis[i]\n",
    "    j.append(tp/(fp+fn+tp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.24606881080551876\n",
      "0.16487261998853636\n",
      "===\n",
      "0.23393939393939395\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "n = np.array(f1)\n",
    "\n",
    "print(n.mean())\n",
    "print(n.std())\n",
    "\n",
    "srt = np.argsort(-n)\n",
    "\n",
    "print(\"===\")\n",
    "print(f1[srt[int(len(srt)/2)]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 11  23 123 124 146 168 183 222 258 278 282 293 304 341 357 382 406 438\n",
      " 443 473]\n"
     ]
    }
   ],
   "source": [
    "z = np.where(n == 0.0)[0]\n",
    "print(z[0:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The car is leaving its parking space. The car is beginning to travel down the road.\n",
      "====\n",
      "S2V:\n",
      "The car is accelerating and making a u-turn to the left. The car is leaving its parking space.\n",
      "The car is merging left and accelerating. The car is leaving its parking space.\n",
      "The car is travelling down the road. The car is at an intersection with a red light.\n",
      "====\n",
      "SDL:\n",
      "The car inches forward because the car in front moves forward.\n",
      "The car is negotiating a left hand curve The car has come to a curve in the road and is turning 180 degrees to the left.\n",
      "The car veers right to pass a vehicle that stopped in the car's lane.\n",
      "The car's windshield wipers run because there is rain on the windshield.\n",
      "The car gets into close proximity of the forward vehicle because the forward vehicle slowed down.\n",
      "The car brakes quickly because traffic ahead brakes.\n",
      "The car remains in the same lane and goes the same speed. Because the car is merging onto the highway with no traffic ahead of it.\n",
      "The car veers left to pass the car on the right.\n",
      "The car performs a rolling stop (illegally) because there is a stop sign.\n",
      "The car veers into the left lane because there are pedestrians in the right.\n"
     ]
    }
   ],
   "source": [
    "case = 473\n",
    "\n",
    "print(phrase_lookup[case])\n",
    "print(\"====\")\n",
    "print(\"S2V:\")\n",
    "for i in s2v[case][0:3]:\n",
    "    print(phrase_lookup[i])\n",
    "print(\"====\")\n",
    "print(\"SDL:\")\n",
    "for i in sdl[case][0:10]:\n",
    "    print(phrase_lookup[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SDL Ranking Average Distance\n",
    "Calculates the average sent2vec distance between the SDL's most-similar samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "2000\n",
      "4000\n",
      "6000\n",
      "8000\n",
      "10000\n",
      "12000\n",
      "14000\n",
      "16000\n",
      "18000\n",
      "20000\n",
      "22000\n",
      "24000\n",
      "26000\n"
     ]
    }
   ],
   "source": [
    "# Average Distance of SDL Ranking\n",
    "import numpy as np\n",
    "\n",
    "avg_dist = np.zeros(len(sdl))\n",
    "\n",
    "for i,sample in enumerate(sdl):\n",
    "    if i%2000 == 0:\n",
    "        print(i)\n",
    "    avg = 0\n",
    "    for closest in sample:\n",
    "        avg+=dist_matrix[i][closest]\n",
    "    avg_dist[i] = avg/len(sample)\n",
    "\n",
    "ranking = np.argsort(avg_dist)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17.79138845407426\n",
      "2049\n"
     ]
    }
   ],
   "source": [
    "print(avg_dist[ranking[-1]])\n",
    "print(len(sdl[ranking[-1]]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SDL Embedding Code\n",
    "Calculates the pairwise distance between SDL Objects. This code should be placed in the SDL_Data_Mining notebook and used after the SDL Objects have been created and the descriptions have been data mined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns a list of unique actors, actions, and scenes\n",
    "\n",
    "actors = []\n",
    "actions = []\n",
    "scenes = []\n",
    "\n",
    "# Find unique identifiers in each category\n",
    "for sdl in sdlObjectList:\n",
    "    for timestep in range(1,len(sdl.actors)+1):\n",
    "        for obj in sdl.actors[str(timestep)]:\n",
    "            if not obj.description in actors:\n",
    "                actors.append(obj.description)\n",
    "            if not obj.action in actions:\n",
    "                actions.append(obj.action)\n",
    "        for obj in sdl.scene[str(timestep)]:\n",
    "            if not obj in scenes:\n",
    "                scenes.append(obj)\n",
    "\n",
    "# Transform lists into (key,index) pairs\n",
    "actor_encoding = {}\n",
    "scene_encoding = {}\n",
    "action_encoding = {}\n",
    "for idx in range(len(actors)):\n",
    "    actor_encoding[actors[idx]] = idx\n",
    "for idx in range(len(scenes)):\n",
    "    scene_encoding[scenes[idx]] = idx\n",
    "for idx in range(len(actions)):\n",
    "    action_encoding[actions[idx]] = idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "- Each sdl object has a 7x21x22 one hot encoding representing its action, actor and scene element\n",
    "- These one hot encodings are stacked on top of each other to produce a 4D tensor [examples x actor x action x scene]\n",
    "- Last element of each dimension represents an NaN value (or empty string for action)\n",
    "\n",
    "For each SDL object in sdlObjectList, 15 (7 x 21 x 22) numpy arrays are generated to represent the 15 time segments in each object\n",
    "\n",
    "'''\n",
    "actor_encoding = {'light vehicle': 0, 'heavy vehicle': 1, 'cyclist': 2, 'pedestrian': 3, 'traffic': 4, 'ego': 5, 'NaN': 6}\n",
    "\n",
    "action_encoding = {'turn': 0, 'turn left': 1, 'turn right': 3, 'merge': 4, 'accelerate': 5, 'brake': 6, 'stop': 7, \n",
    "                   'forward': 8, 'walk': 9, 'park': 10, 'drive': 11, 'reverse': 12, 'merge center': 13, 'merge left': 14, \n",
    "                   'merge right': 15, 'turn through': 16, 'merge u turn': 17, 'u-turn': 18, 'NaN': 19, '':20}\n",
    "\n",
    "scene_encoding = {'intersection': 0, 'crosswalk': 1, 'bridge': 2, 'green light': 3, 'stop sign': 4, 'yield sign': 5, 'sign': 6, \n",
    "                  'u-turn': 7, 'traffic light': 8, 'traffic signal': 9, 'turn lane': 10, 'crosswalks': 11, 'green traffic light': 12, \n",
    "                  'light': 13, 'lights': 14, 'red light': 15, 'red traffic light': 16, 'signs': 17, 'traffic lights': 18, \n",
    "                  'yellow light': 19, 'yellow traffic light': 20, 'NaN': 21}\n",
    "\n",
    "one_hot_sdlEmbedding = []\n",
    "\n",
    "examples = [3, 413]\n",
    "for example in range(len(sdlObjectList)): #loops through 6996 sdl objects in sdlObjectList\n",
    "    # Each sdl object has a 7x21x22 one hot encoding representing its action, actor and scene element\n",
    "    for a in range(len(sdlObjectList[example].actors)): #loops through 15 time segments\n",
    "        #print(\"time segments: \", len(sdlObjectList[example].actors))\n",
    "        #print(a)\n",
    "        indices = np.zeros((7,21,22))\n",
    "        actorsIndex = str(a+1)\n",
    "        actor_list = []\n",
    "        action_list = []\n",
    "        scene_list = []\n",
    "        for j in range(len(sdlObjectList[example].actors[actorsIndex])):\n",
    "            actor_list.append(sdlObjectList[example].actors[actorsIndex][j].description)\n",
    "            action_list.append(sdlObjectList[example].actors[actorsIndex][j].action)\n",
    "\n",
    "        scene_list.append(sdlObjectList[example].scene[actorsIndex])\n",
    "\n",
    "        #print(\"actor list: \", actor_list)\n",
    "        #print(\"action list: \", action_list)\n",
    "        #print(\"scene list: \", scene_list)\n",
    "\n",
    "        actor_indices = []\n",
    "        action_indices = []\n",
    "        scene_indices = []\n",
    "\n",
    "\n",
    "        if(len(actor_list) != len(action_list)):\n",
    "            print(\"Actor and action list don't match up, this may cause 1 to 1 actor to action correspondence errors\")\n",
    "            break\n",
    "\n",
    "        for a_index in actor_list:\n",
    "            actor_indices.append(actor_encoding[a_index])\n",
    "\n",
    "        for act_index in action_list:\n",
    "            action_indices.append(action_encoding[act_index])\n",
    "\n",
    "        if( ((len(scene_list)) > 0) and scene_list[0] != 'NaN'):\n",
    "            for i in scene_list:\n",
    "                for j in i:\n",
    "                    scene_indices.append(scene_encoding[j])\n",
    "        else:\n",
    "            scene_indices.clear()\n",
    "            scene_indices.append(21)\n",
    "\n",
    "        if(len(actor_indices) != len(action_indices)):\n",
    "            print(\"make sure each actor is matched up with an action\")\n",
    "            break\n",
    "        # if each sdl has an actor paired with each action, how do we account for multiple scene elements\n",
    "        #print(\"actor indices: \", actor_indices)\n",
    "        #print(\"action indices: \", action_indices)\n",
    "        #print(\"scene indices: \", scene_indices)\n",
    "\n",
    "        if(len(scene_indices) > 0):\n",
    "            for scene_index in scene_indices:\n",
    "                for i, actor_index in enumerate(actor_indices):\n",
    "                # since there is a one to one mapping between actor and actions, we can use the same index\n",
    "                action_index = action_indices[i]\n",
    "                #print(\"for\")\n",
    "                #print(\"actor index: \", actor_index, \" action index: \", action_index, \" scene_index: \", scene_index)\n",
    "                indices[actor_index][action_index][scene_index] = 1.0\n",
    "        else:\n",
    "            scene_index = 21\n",
    "            for i, actor_index in enumerate(actor_indices):\n",
    "                action_index = action_indices[i]\n",
    "                #print(\"else\")\n",
    "                #print(\"actor index: \", actor_index, \" action index: \", action_index, \" scene_index: \", scene_index)\n",
    "                indices[actor_index][action_index][scene_index] = 1.0\n",
    "\n",
    "        one_hot_sdlEmbedding.append(tf.convert_to_tensor(indices))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dist(e1,e2):\n",
    "    return np.linalg.norm(e1-e2) # Euclidean Distance\n",
    "\n",
    "dist_matrix = np.zeros((matrix_size,matrix_size))\n",
    "\n",
    "for i in range(matrix_size):\n",
    "    if i%500 == 0:\n",
    "        print(i)\n",
    "    dist_matrix[i][i] = 0\n",
    "    for j in range(i+1,matrix_size):\n",
    "        d = dist(one_hot_sdlEmbedding[i],one_hot_sdlEmbedding[j])\n",
    "        dist_matrix[i][j] = d\n",
    "        dist_matrix[j][i] = d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_to_file(dist_matrix,\"sdl_dist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
