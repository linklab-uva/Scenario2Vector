{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "import numpy as np\n",
    "\n",
    "path = \".\"\n",
    "filename = \"crowd_dict.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"%s/%s\"%(path,filename),\"rb\") as _in:\n",
    "    similarity_dataset = pkl.load(_in)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Author's Note:\n",
    "This code aligns the textual description with the video clips. In order to get the textual\n",
    "  description corresponding to key #5 in the similarity dataset, simply call phrase_lookup[5]\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd # Pandas library enables data manipulation\n",
    "data_url = \"./revisedBDDX.csv\"\n",
    "def load_bddx_data(csv_name):\n",
    "    column_names = ['Index', 'InputVideo', '1S', '1E', '1A', '1J', '2S', '2E', '2A', '2J', '3S', '3E', '3A', '3J',\n",
    "                    '4S', '4E', '4A', '4J','5S', '5E', '5A', '5J','6S', '6E', '6A', '6J','7S', '7E', '7A', '7J',\n",
    "                    '8S', '8E', '8A', '8J','9S', '9E', '9A', '9J','10S', '10E', '10A', '10J','11S', '11E', '11A', '11J',\n",
    "                    '12S', '12E', '12A', '12J','13S', '13E', '13A', '13J','14S', '14E', '14A', '14J','15S', '15E', '15A', '15J']\n",
    "    \n",
    "    return pd.read_csv(csv_name, names=column_names)\n",
    "\n",
    "bddx = load_bddx_data(data_url)\n",
    "bddx = bddx.drop(['1S', '1E','2S', '2E','3S', '3E','4S', '4E','5S', '5E','6S', '6E','7S', '7E','8S', '8E','9S', '9E','10S', '10E','11S', '11E','12S', '12E','13S', '13E','14S', '14E','15S', '15E', ], axis=1)\n",
    "bddx = bddx.fillna(\"\")\n",
    "\n",
    "bddx['1AJ'] = bddx[['1A', '1J']].agg(' '.join, axis=1)\n",
    "bddx['2AJ'] = bddx[['2A', '2J']].agg(' '.join, axis=1)\n",
    "bddx['3AJ'] = bddx[['3A', '3J']].agg(' '.join, axis=1)\n",
    "bddx['4AJ'] = bddx[['4A', '4J']].agg(' '.join, axis=1)\n",
    "bddx['5AJ'] = bddx[['5A', '5J']].agg(' '.join, axis=1)\n",
    "bddx['6AJ'] = bddx[['6A', '6J']].agg(' '.join, axis=1)\n",
    "bddx['7AJ'] = bddx[['7A', '7J']].agg(' '.join, axis=1)\n",
    "bddx['8AJ'] = bddx[['8A', '8J']].agg(' '.join, axis=1)\n",
    "bddx['9AJ'] = bddx[['9A', '9J']].agg(' '.join, axis=1)\n",
    "bddx['10AJ'] = bddx[['10A', '10J']].agg(' '.join, axis=1)\n",
    "bddx['11AJ'] = bddx[['11A', '11J']].agg(' '.join, axis=1)\n",
    "bddx['12AJ'] = bddx[['12A', '12J']].agg(' '.join, axis=1)\n",
    "bddx['13AJ'] = bddx[['13A', '13J']].agg(' '.join, axis=1)\n",
    "bddx['14AJ'] = bddx[['14A', '14J']].agg(' '.join, axis=1)\n",
    "bddx['15AJ'] = bddx[['15A', '15J']].agg(' '.join, axis=1)\n",
    "\n",
    "bddx = bddx.drop(['Index', '1A', '1J', '2A', '2J', '3A', '3J', '4A', '4J', '5A', '5J', '6A', '6J', '7A', '7J', '8A', '8J', '9A', '9J', '10A', '10J', '11A', '11J', '12A', '12J', '13A', '13J', '14A', '14J', '15A', '15J', ], axis=1)\n",
    "bddx = bddx.drop(bddx.index[0])\n",
    "\n",
    "sdlList = []\n",
    "for index, row in bddx.iterrows():\n",
    "    sdlList.append(row.astype(str))\n",
    "    \n",
    "sdlStatements = []\n",
    "for i in range(len(sdlList)):\n",
    "    sdlStatements.append({'1': sdlList[i]['1AJ'], '2': sdlList[i]['2AJ'], '3': sdlList[i]['3AJ'], '4': sdlList[i]['4AJ'], \n",
    "                        '5': sdlList[i]['5AJ'], '6': sdlList[i]['6AJ'], '7': sdlList[i]['7AJ'], '8': sdlList[i]['8AJ'], \n",
    "                        '9': sdlList[i]['9AJ'], '10': sdlList[i]['10AJ'], '11': sdlList[i]['11AJ'], '12': sdlList[i]['12AJ'], \n",
    "                        '13': sdlList[i]['13AJ'], '14': sdlList[i]['14AJ'], '15': sdlList[i]['15AJ']})\n",
    "\n",
    "phrase_lookup = []\n",
    "\n",
    "for i in range(len(sdlStatements)):\n",
    "    keysTemp = list(sdlStatements[i].keys())\n",
    "    for j in keysTemp:\n",
    "        if (sdlStatements[i][j]==\" \"):\n",
    "            continue\n",
    "        else:\n",
    "            phrase_lookup.append(sdlStatements[i][j])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: This is where metric stuff will go\n",
    "def read_embeddings(embeddings_path):\n",
    "    \"\"\"Arguments:\n",
    "        - embeddings_path: path to the embeddings\n",
    "    \"\"\"\n",
    "    with open(embeddings_path, 'r') as in_stream:\n",
    "        embeddings = []\n",
    "        for line in in_stream:\n",
    "            line = '['+line.replace(' ',',')+']'\n",
    "            embeddings.append(eval(line))\n",
    "        return embeddings\n",
    "    return []\n",
    "\n",
    "embeddings = np.array(read_embeddings(\"./bddx_embeddings.txt\"))\n",
    "\n",
    "def sent2vec_metric(a,b): # a and b should be indices taken from similarity_dataset\n",
    "    return np.linalg.norm(embeddings[a]-embeddings[b]) # Euclidean Distance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Author's Note:\n",
    "How to change this code:\n",
    "  Simply change \"metric = sent2vec_metric\" to a different metric function. The metric function\n",
    "  should take as input two indices taken from the similarity_dataset.\n",
    "How to read metric_output:\n",
    "  For a given base index (e.g., 15096), it shows which ranking each video has under the metric\n",
    "  e.g., [1,0,2,5,3,4] mean that the second video (index 23555) is the most similar, and the\n",
    "  fourth video (index 17262) is the least similar.\n",
    "\"\"\"\n",
    "\n",
    "metric_output = {}\n",
    "metric = sent2vec_metric # This should be a function that takes two indices as inputs\n",
    "\n",
    "for base in similarity_dataset:\n",
    "    metric_output[base] = [0]*len(similarity_dataset[base])\n",
    "    output = []\n",
    "    for comparison in similarity_dataset[base]:\n",
    "        output.append( metric(base,comparison) )\n",
    "    order = np.argsort(output)\n",
    "    for i,sort_order in enumerate(order):\n",
    "        metric_output[base][sort_order] = i\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 0, 2, 5, 3, 4]\n",
      "[14293, 23555, 2079, 24844, 17262, 15380]\n",
      "[5, 0, 3, 1, 2, 4]\n",
      "[19200, 15559, 2659, 11364, 898, 18227]\n",
      "[4, 2, 5, 1, 0, 3]\n",
      "[1399, 5208, 10498, 9388, 17117, 1904]\n",
      "[3, 1, 0, 4, 5, 2]\n",
      "[738, 14371, 5451, 24023, 26526, 13481]\n",
      "[5, 1, 3, 2, 4, 0]\n",
      "[18824, 13899, 24471, 2071, 2451, 8295]\n"
     ]
    }
   ],
   "source": [
    "brk = 5\n",
    "for key in metric_output:\n",
    "    print(metric_output[key])\n",
    "    print(similarity_dataset[key])\n",
    "    brk-=1\n",
    "    if brk <= 0:\n",
    "        break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
