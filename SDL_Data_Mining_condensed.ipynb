{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SDL_Data_Mining_condensed.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "W-buGJ2c-_Cc"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NgEHONRaZqJB",
        "colab": {}
      },
      "source": [
        "# Python ≥3.5 is required\n",
        "import sys\n",
        "assert sys.version_info >= (3, 5)\n",
        "\n",
        "# Scikit-Learn ≥0.20 is required\n",
        "import sklearn\n",
        "assert sklearn.__version__ >= \"0.20\"\n",
        "\n",
        "# Common imports\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# NLTK to find word stems\n",
        "import nltk"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "8G_67Dfy_Dok"
      },
      "source": [
        "# Data Cleaning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "eCF14nW7bVre",
        "colab": {}
      },
      "source": [
        "import pandas as pd # Pandas library enables data manipulation\n",
        "data_url = \"https://raw.githubusercontent.com/linklab-uva/Scenario2Vector/master/BDDX.csv?token=AH3QIX7CFN4LG3QSSDV5HOK67EBYU\"\n",
        "def load_bddx_data(csv_name):\n",
        "    column_names = ['Index', 'InputVideo', '1S', '1E', '1A', '1J', '2S', '2E', '2A', '2J', '3S', '3E', '3A', '3J',\n",
        "                    '4S', '4E', '4A', '4J','5S', '5E', '5A', '5J','6S', '6E', '6A', '6J','7S', '7E', '7A', '7J',\n",
        "                    '8S', '8E', '8A', '8J','9S', '9E', '9A', '9J','10S', '10E', '10A', '10J','11S', '11E', '11A', '11J',\n",
        "                    '12S', '12E', '12A', '12J','13S', '13E', '13A', '13J','14S', '14E', '14A', '14J','15S', '15E', '15A', '15J']\n",
        "    \n",
        "    return pd.read_csv(csv_name, names=column_names)\n",
        "bddx = load_bddx_data(data_url)\n",
        "bddx = bddx.drop(['1S', '1E','2S', '2E','3S', '3E','4S', '4E','5S', '5E','6S', '6E','7S', '7E','8S', '8E','9S', '9E','10S', '10E','11S', '11E','12S', '12E','13S', '13E','14S', '14E','15S', '15E', ], axis=1)\n",
        "bddx = bddx.fillna(\"\")\n",
        "\n",
        "bddx['1AJ'] = bddx[['1A', '1J']].agg(' '.join, axis=1)\n",
        "bddx['2AJ'] = bddx[['2A', '2J']].agg(' '.join, axis=1)\n",
        "bddx['3AJ'] = bddx[['3A', '3J']].agg(' '.join, axis=1)\n",
        "bddx['4AJ'] = bddx[['4A', '4J']].agg(' '.join, axis=1)\n",
        "bddx['5AJ'] = bddx[['5A', '5J']].agg(' '.join, axis=1)\n",
        "bddx['6AJ'] = bddx[['6A', '6J']].agg(' '.join, axis=1)\n",
        "bddx['7AJ'] = bddx[['7A', '7J']].agg(' '.join, axis=1)\n",
        "bddx['8AJ'] = bddx[['8A', '8J']].agg(' '.join, axis=1)\n",
        "bddx['9AJ'] = bddx[['9A', '9J']].agg(' '.join, axis=1)\n",
        "bddx['10AJ'] = bddx[['10A', '10J']].agg(' '.join, axis=1)\n",
        "bddx['11AJ'] = bddx[['11A', '11J']].agg(' '.join, axis=1)\n",
        "bddx['12AJ'] = bddx[['12A', '12J']].agg(' '.join, axis=1)\n",
        "bddx['13AJ'] = bddx[['13A', '13J']].agg(' '.join, axis=1)\n",
        "bddx['14AJ'] = bddx[['14A', '14J']].agg(' '.join, axis=1)\n",
        "bddx['15AJ'] = bddx[['15A', '15J']].agg(' '.join, axis=1)\n",
        "\n",
        "bddx = bddx.drop(['Index', '1A', '1J', '2A', '2J', '3A', '3J', '4A', '4J', '5A', '5J', '6A', '6J', '7A', '7J', '8A', '8J', '9A', '9J', '10A', '10J', '11A', '11J', '12A', '12J', '13A', '13J', '14A', '14J', '15A', '15J', ], axis=1)\n",
        "bddx = bddx.drop(bddx.index[0])"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "l7GCX7cn_H2h"
      },
      "source": [
        "# SDL Class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TzdQb5tazHLa",
        "colab": {}
      },
      "source": [
        "class Actor:\n",
        "    def __init__(self, description):\n",
        "        \"\"\"\n",
        "        self.description should be one of the following:\n",
        "          ego\n",
        "          light vehicle\n",
        "          heavy vehicle\n",
        "          cyclist\n",
        "          pedestrian\n",
        "        \"\"\"\n",
        "        self.description = description\n",
        "        self.action = \"\""
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Hzde2fYDzHLe",
        "colab": {}
      },
      "source": [
        "class SDL_Util:\n",
        "    def __init__(self):\n",
        "        self.stemmer = nltk.stem.PorterStemmer()\n",
        "        # stemmer allows us to match words with the same roots: e.g., it identifies \"turns\", \"turning\", and \"turn\" as the same word\n",
        "        # But it recognizes \"slow\" and \"slowly\" as different, and it thinks \"go\" and \"goes\" are different\n",
        "\n",
        "        self.actor_list = {'car':'light vehicle',\n",
        "                           'bus':'heavy vehicle',\n",
        "                           'truck':'heavy vehicle',\n",
        "                           'cyclist':'cyclist',\n",
        "                           'pedestrian':'pedestrian',\n",
        "                           'ambulance':'heavy vehicle',\n",
        "                           'minivan':'light vehicle',\n",
        "                           'traffic':'traffic',\n",
        "                           'the car':'light vehicle'\n",
        "                           }\n",
        "        self.scene_list = ['intersection',\n",
        "                           'crosswalk',\n",
        "                           'bridge',\n",
        "                           'light',\n",
        "                           'sign',\n",
        "                           'traffic light',\n",
        "                           'traffic signal',\n",
        "                           'turn lane',\n",
        "                           ]\n",
        "\n",
        "        init_action_list = {'turn':'turn',\n",
        "                            'merge':'merge',\n",
        "                            'swerve':'merge',\n",
        "                            'veer':'merge',\n",
        "                            'switch':'merge',\n",
        "                            'accelerate':'accelerate',\n",
        "                            'pick':'accelerate',\n",
        "                            'brake':'brake',\n",
        "                            'slow':'brake',\n",
        "                            'reduce':'brake',\n",
        "                            'decelerate':'brake',\n",
        "                            'stop':'stop',\n",
        "                            'wait':'stop',\n",
        "                            'sit':'stop',\n",
        "                            'forward':'forward',\n",
        "                            'move':'forward',\n",
        "                            'stay':'forward',\n",
        "                            'maintain':'forward',\n",
        "                            'proceeds':'forward',\n",
        "                            'proceed':'forward',\n",
        "                            'inch':'forward',\n",
        "                            'pass':'forward',\n",
        "                            'roll':'forward',\n",
        "                            'advance':'forward',\n",
        "                            'drive':'drive',\n",
        "                            'steer':'drive',\n",
        "                            'go':'drive',\n",
        "                            'goes':'drive',\n",
        "                            'head':'drive',\n",
        "                            'pull':'drive',\n",
        "                            'travel':'drive',\n",
        "                            'flow':'drive',\n",
        "                            'reverse':'reverse',\n",
        "                            'walk':'walk',\n",
        "                            'cross':'walk',\n",
        "                            'park':'park',\n",
        "                            'drift':'forward', # Not sure about this one, but it's not changing lanes so I'm calling it \"forward\"\n",
        "                            'block':'stop', # Vehicles that are blocking generally are stopped in the path of the ego\n",
        "                            'enter':'merge',\n",
        "                            'straighten':'forward',\n",
        "                            'follow':'forward',\n",
        "                            'shift':'merge',\n",
        "                            'change':'merge',\n",
        "                            'stand':'stop', # Standing still\n",
        "                            'curve':'forward',\n",
        "                           }\n",
        "        self.adjective_action = {'clear':'_negative', # traffic is clear\n",
        "                                 'stationary':'stop', # car is stationary\n",
        "                                 'complete':'stop', # is at a complete stop\n",
        "                                 'heavy':'forward', # traffic is heavy\n",
        "                                 'accelerating':'accelerate', # car is accelerating\n",
        "                                 'light':'_negative', # traffic is light\n",
        "                                 'slow':'forward', # traffic is slow\n",
        "                                 'parallel':'reverse', # car is parallel parking\n",
        "                                 'rolling':'forward', # car is rolling forward\n",
        "                                 'driving':'drive', # car is driving\n",
        "                                 'full':'stop', # car is at a full stop\n",
        "                                 'stopped':'stop', # car is stopped\n",
        "                                 'busy':'forward', # traffic is busy\n",
        "                                 'double':'stop', # car is double parked\n",
        "                                 'double-parked':'stop', # car is double-parked\n",
        "                                 'idle':'stop', # car is idle\n",
        "                                 'stopping':'brake', # car is stopping\n",
        "                                 'minimal':'_negative', # traffic is minimal\n",
        "                                 'empty':'_negative', # traffic is empty\n",
        "                                 'moderate':'forward', # traffic is moderate\n",
        "                                }\n",
        "        self.action_list = {}\n",
        "        for a in init_action_list:\n",
        "            self.action_list[self.stemmer.stem(a)] = init_action_list[a]\n",
        "\n",
        "        self.light_status = [\"green\",\"yellow\",\"red\"]\n",
        "        self.directions = [\"left\",\"right\",\"u-turn\",\"uturn\",\"through\",\"backward\",\"down\",\"straight\"]\n",
        "\n",
        "        self.debug = {\"_None\":[]}\n",
        "    def update_debug(self,word,phrase):\n",
        "        if not word in self.debug:\n",
        "            self.debug[word] = []\n",
        "        self.debug[word].append(phrase)\n",
        "\n",
        "util = SDL_Util()\n",
        "\n",
        "class SDL:\n",
        "  def __init__(self, index, statements, link):\n",
        "    self.statements = statements\n",
        "    self.index = index\n",
        "    self.videoLink = link\n",
        "    \n",
        "    self.actors = {'1':[], '2':[], '3':[], '4':[], '5':[], '6':[], '7':[], \n",
        "                   '8':[], '9':[], '10':[], '11':[], '12':[], '13':[], '14':[], '15':[]}\n",
        "    self.scene = {'1':[], '2':[], '3':[], '4':[], '5':[], '6':[], '7':[], \n",
        "                   '8':[], '9':[], '10':[], '11':[], '12':[], '13':[], '14':[], '15':[]}\n",
        "        \n",
        "  def getDescriptors(self, statement, timeSegment): \n",
        "\n",
        "    init_phrase = nltk.word_tokenize(statement.lower())\n",
        "    phrase = nltk.pos_tag(init_phrase)\n",
        "\n",
        "    if(statement == \"No Data Recorded\"):\n",
        "      self.actors[timeSegment].append(Actor(\"NaN\"))\n",
        "      self.actors[timeSegment][-1].action = \"NaN\"\n",
        "      self.scene[timeSegment].append(\"NaN\")\n",
        "    \n",
        "    skip = 0\n",
        "    actor_locs = []\n",
        "    for idx,word in enumerate(phrase):\n",
        "        while skip > 0:\n",
        "            skip-=1\n",
        "            continue\n",
        "        if word[1][0] == \"N\": # Word is a noun\n",
        "            element = word[0]\n",
        "            for i in range(idx+1,len(phrase)):\n",
        "                if phrase[i][1][0] == \"N\": # consecutive nouns should be together, e.g. \"traffic light\"\n",
        "                    element+=\" \"+phrase[i][0]\n",
        "                    skip+=1\n",
        "                elif element == \"traffic\" and (phrase[i][0] == \"light\" or phrase[i][0] == \"signal\"):\n",
        "                    element+=\" \"+phrase[i][0]\n",
        "                    skip+=1\n",
        "                else:\n",
        "                    break\n",
        "            if element == \"car\" and (idx > 0 and phrase[idx-1][0] == \"the\") and (idx+1 < len(phrase) and phrase[idx+1] != 'in'):\n",
        "                element = \"the car\" # \"the car\" always refers to the ego, except in the case of \"the car in front\"\n",
        "            elif element == \"sign\":\n",
        "                # Find the type of sign, e.g. \"stop sign\"\n",
        "                if idx > 0 and phrase[idx-1][1][0] == \"J\":\n",
        "                    element = phrase[idx-1][0]+\" \"+element\n",
        "            if util.stemmer.stem(element) in util.actor_list or util.stemmer.stem(element) in util.scene_list:\n",
        "                actor_locs.append((element,idx))\n",
        "        elif word[1] == \".\":\n",
        "            actor_locs.append((\".\",idx))\n",
        "    for idx in range(len(actor_locs)):\n",
        "        if idx+1 < len(actor_locs):\n",
        "            search_phrase = phrase[actor_locs[idx][1]:actor_locs[idx+1][1]]\n",
        "        else:\n",
        "            search_phrase = phrase[actor_locs[idx][1]:]\n",
        "        if util.stemmer.stem(actor_locs[idx][0]) in util.actor_list:\n",
        "            is_positive = True\n",
        "            negative = [\"no\",\"clear\",\"lack\",\"free\"]\n",
        "            for i in range(max(0,actor_locs[idx][1]-3),actor_locs[idx][1]):\n",
        "                if phrase[i][0] in negative:\n",
        "                    is_positive = False # don't add an actor if the phrase is \"there are no cars\"\n",
        "                    break\n",
        "            if is_positive:\n",
        "                self.compose_actor(search_phrase,actor_locs[idx][0],timeSegment)\n",
        "        elif util.stemmer.stem(actor_locs[idx][0]) in util.scene_list:\n",
        "            #TODO: Check lights to see if the color is 1 word earlier (e.g., \"red light\")\n",
        "            self.compose_scene(search_phrase,actor_locs[idx][0],timeSegment)\n",
        "                \n",
        "  def compose_actor(self,phrase,actor,timeSegment):\n",
        "    if len(self.actors[timeSegment]) == 0:\n",
        "        self.actors[timeSegment].append(Actor(\"ego\"))\n",
        "        action = self.find_action(phrase)\n",
        "        if action and action != \"_negative\":\n",
        "            self.actors[timeSegment][-1].action = action\n",
        "    elif actor == 'the car':\n",
        "        return # \"the car\" always refers to ego\n",
        "    elif util.stemmer.stem(actor) == 'pedestrian': # Pedestrians always walk\n",
        "        self.actors[timeSegment].append(Actor(util.actor_list[util.stemmer.stem(actor)]))\n",
        "        self.actors[timeSegment][-1].action = util.action_list[util.stemmer.stem(\"walk\")]\n",
        "    else:\n",
        "        action = self.find_action(phrase)\n",
        "        if action == \"_negative\":\n",
        "            return # don't add an actor if the phrase is \"the traffic is clear\"\n",
        "        self.actors[timeSegment].append(Actor(util.actor_list[util.stemmer.stem(actor)]))\n",
        "        if action:\n",
        "            self.actors[timeSegment][-1].action = action\n",
        "            \n",
        "  def find_action(self,phrase):\n",
        "    delay_verbs = [\"come\",\"make\",\"continu\",\"begin\",\"start\",\"complet\",\"tri\"] # Verbs where the actual action is later in the sentence\n",
        "    exist_verbs = [\"is\",\"are\",\"remain\"]\n",
        "    action = \"\"\n",
        "    action_index = 0\n",
        "    for i in range(1,len(phrase)):\n",
        "        if phrase[i][1][0:2] == \"RB\": # Ignore adverbs\n",
        "            continue\n",
        "        elif phrase[i][1] == \".\": # Sentence has ended. Stop looking for a verb\n",
        "            break\n",
        "        if phrase[i][1][0] == \"V\":\n",
        "            action = phrase[i][0]\n",
        "            action_index = i\n",
        "            for j in range(i+1,len(phrase)):\n",
        "                if phrase[j][1][0:2] == \"RB\": # Ignore adverbs\n",
        "                    continue\n",
        "                elif phrase[j][1][0] == \"V\": # If there are multiple verbs in a row, take the last\n",
        "                    if phrase[j][0] == \"left\": # \"left\" is getting misidentified as a verb, ignore it\n",
        "                        break\n",
        "                    action = phrase[j][0]\n",
        "                    action_index = j\n",
        "                else:\n",
        "                    break\n",
        "            break\n",
        "    if action == \"\":\n",
        "        util.update_debug(\"_None\",phrase)\n",
        "        return None\n",
        "    elif util.stemmer.stem(action) in util.action_list:\n",
        "        action = util.action_list[util.stemmer.stem(action)]\n",
        "    # Start of hand-crafted rules exclusive to this dataset\n",
        "    elif action_index+1 < len(phrase) and phrase[action_index+1][0] == \"forward\":\n",
        "        return util.action_list[util.stemmer.stem(\"forward\")]\n",
        "    elif util.stemmer.stem(action) in delay_verbs:\n",
        "        better_action = False\n",
        "        for i in range(action_index+1,len(phrase)):\n",
        "            if phrase[i][1][0:2] == \"RB\": # Ignore adverbs\n",
        "                continue\n",
        "            if util.stemmer.stem(phrase[i][0]) in util.action_list:\n",
        "                word = phrase[i][0]\n",
        "                for j in range(i+1,len(phrase)):\n",
        "                    if phrase[j][1][0:2] == \"RB\": # Ignore adverbs\n",
        "                        continue\n",
        "                    elif phrase[i][1][0] == \"V\" and phrase[j][1][0] == \"V\":\n",
        "                        word = phrase[j][0]\n",
        "                    elif phrase[i][1][0] == \"N\" and phrase[j][1][0] == \"N\":\n",
        "                        word = phrase[j][0]\n",
        "                    else:\n",
        "                        break\n",
        "                if util.stemmer.stem(word) in util.action_list:\n",
        "                    action = util.action_list[util.stemmer.stem(word)]\n",
        "                    better_action = True\n",
        "                elif word == \"hand\":\n",
        "                    action = util.action_list[\"turn\"]\n",
        "                    better_action = True\n",
        "            elif phrase[i][0] in util.directions:\n",
        "                action = util.action_list[\"drive\"]\n",
        "                better_action = True\n",
        "            if better_action:\n",
        "                break\n",
        "        if not better_action:\n",
        "            if util.stemmer.stem(action) == \"continu\":\n",
        "                # The only continues unclassified at this point are \"forward\"\n",
        "                return util.action_list[util.stemmer.stem(\"forward\")]\n",
        "            elif util.stemmer.stem(action) == util.stemmer.stem(\"come\"):\n",
        "                if action_index+1 < len(phrase) and phrase[action_index+1][0] == \"to\":\n",
        "                    return util.action_list[util.stemmer.stem(\"stop\")] # the car comes to a stop\n",
        "                else:\n",
        "                    action = \"drive\"\n",
        "            else:\n",
        "                util.update_debug(util.stemmer.stem(action),phrase)\n",
        "                return None\n",
        "    elif util.stemmer.stem(action) in exist_verbs:\n",
        "        if action_index+1 < len(phrase) and phrase[action_index+1][0] == \"at\":\n",
        "            # traffic is at a stop / standstill / red\n",
        "            return util.action_list[util.stemmer.stem(\"stop\")]\n",
        "        adj = \"\"\n",
        "        for i in range(action_index+1,len(phrase)):\n",
        "            if phrase[i][1][0] == \"R\":\n",
        "                continue # Ignore adverbs\n",
        "            elif phrase[i][1][0] == \"J\":\n",
        "                adj = phrase[i][0]\n",
        "                break\n",
        "            else:\n",
        "                break\n",
        "        if adj in util.adjective_action:\n",
        "            action = util.adjective_action[adj]\n",
        "        else:\n",
        "            util.update_debug(util.stemmer.stem(action),phrase)\n",
        "            return None\n",
        "    elif util.stemmer.stem(action) == util.stemmer.stem(\"speed\"):\n",
        "        if action_index+1 < len(phrase) and phrase[action_index+1][0] == \"up\":\n",
        "            return util.action_list[util.stemmer.stem(\"accelerate\")]\n",
        "        elif action_index+1 < len(phrase) and phrase[action_index+1][0] == \"down\":\n",
        "            return util.action_list[util.stemmer.stem(\"forward\")]\n",
        "        else:\n",
        "            util.update_debug(util.stemmer.stem(action),phrase)\n",
        "            return None\n",
        "    elif util.stemmer.stem(action) == util.stemmer.stem(\"back\"):\n",
        "        if action == \"backed\" and action_index > 0 and phrase[action_index-1][0] == \"is\":\n",
        "            return util.action_list[util.stemmer.stem(\"stop\")] # traffic is backed up\n",
        "        else:\n",
        "            return util.action_list[util.stemmer.stem(\"reverse\")]\n",
        "    elif util.stemmer.stem(action) == util.stemmer.stem(\"clear\"):\n",
        "        if action_index > 0 and phrase[action_index-1][0] == \"to\":\n",
        "            return util.action_list[util.stemmer.stem(\"forward\")] # waiting for traffic to clear\n",
        "        else:\n",
        "            return \"_negative\" # traffic has cleared\n",
        "    else:\n",
        "        util.update_debug(util.stemmer.stem(action),phrase)\n",
        "        return None\n",
        "\n",
        "    if action == \"drive\": # \"drive\" needs more information\n",
        "        direction = self.find_direction(phrase,action_index)\n",
        "        if direction == \"left\" or direction == \"right\":\n",
        "            return \"turn \"+direction\n",
        "        elif direction == \"through\" or direction == \"down\" or direction == \"straight\":\n",
        "            return \"forward\"\n",
        "        elif direction == \"backward\":\n",
        "            return \"reverse\"\n",
        "        elif direction == \"u-turn\":\n",
        "            return \"u-turn\"\n",
        "        else:\n",
        "            return \"forward\"\n",
        "    elif action == \"turn\":\n",
        "        direction = self.find_direction(phrase,action_index)\n",
        "        if direction == \"left\" or direction == \"right\":\n",
        "            return \"turn \"+direction\n",
        "        elif direction == \"u-turn\":\n",
        "            return \"u-turn\"\n",
        "        else:\n",
        "            return \"turn\"\n",
        "    elif action == \"merge\":\n",
        "        direction = self.find_direction(phrase,action_index)\n",
        "        if direction == \"left\" or direction == \"right\":\n",
        "            return \"merge \"+direction\n",
        "        else:\n",
        "            return \"merge\"\n",
        "    else:\n",
        "        return action\n",
        "    \n",
        "  def find_direction(self,phrase,index):\n",
        "    if index > 0 and (phrase[index-1][0] == \"left\" or phrase[index-1][0] == \"right\"):\n",
        "        return phrase[index-1][0]\n",
        "    for i in range(index+1,len(phrase)):\n",
        "        if phrase[i][0] in util.directions:\n",
        "            if phrase[i][0] == \"left\":\n",
        "                if i+2 < len(phrase) and phrase[i+1][0] == \"to\" and phrase[i+2][0] == \"right\":\n",
        "                    return \"right\"\n",
        "                else:\n",
        "                    return \"left\"\n",
        "            elif phrase[i][0] == \"right\":\n",
        "                if i+2 < len(phrase) and phrase[i+1][0] == \"to\" and phrase[i+2][0] == \"left\":\n",
        "                    return \"left\"\n",
        "                else:\n",
        "                    return \"right\"\n",
        "            elif phrase[i][0] == \"u-turn\" or phrase[i][0] == \"uturn\":\n",
        "                return \"u-turn\"\n",
        "            else:\n",
        "                return phrase[i][0]\n",
        "        elif phrase[i][0] == \"front\" and (i > 0 and phrase[i-1][0] == \"in\"):\n",
        "            #n-gram \"in front\"\n",
        "            return \"center\"\n",
        "        elif phrase[i][0] == \"u\" and (i+1 < len(phrase) and phrase[i+1][0] == \"turn\"):\n",
        "            #n-gram \"u turn\"\n",
        "            return \"u-turn\"\n",
        "        elif phrase[i][0] == \"its\" and (i+1 < len(phrase) and phrase[i+1][0] == \"lane\"):\n",
        "            #n-gram \"its lane\"\n",
        "            return \"center\"\n",
        "        if phrase[i][1][0] == \"V\":\n",
        "            return None\n",
        "    return None\n",
        "            \n",
        "  def compose_scene(self,phrase,scene,timeSegment):\n",
        "    element = scene.split(\" \")\n",
        "    if element[-1] == \"light\":\n",
        "        status = \"\"\n",
        "        for ls in util.light_status:\n",
        "            for word in phrase:\n",
        "                if word[0] == ls:\n",
        "                    status = ls\n",
        "                    break\n",
        "            if status != \"\":\n",
        "                break\n",
        "        if status != \"\":\n",
        "            self.scene[timeSegment].append(status+\" \"+scene)\n",
        "            return\n",
        "        else:\n",
        "            self.scene[timeSegment].append(scene)\n",
        "            return\n",
        "    else:\n",
        "        self.scene[timeSegment].append(scene)\n",
        "        return\n",
        "\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-c32LWvHmC3x",
        "colab": {}
      },
      "source": [
        "sdlList = []\n",
        "for index, row in bddx.iterrows():\n",
        "    sdlList.append(row.astype(str))\n",
        "assert len(sdlList) == 6996, \"length of sdl list should be 6996\""
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "AquJdlyFuF0N",
        "colab": {}
      },
      "source": [
        "sdlStatements = []\n",
        "for i in range(len(sdlList)):\n",
        "  sdlStatements.append({'1': sdlList[i]['1AJ'], '2': sdlList[i]['2AJ'], '3': sdlList[i]['3AJ'], '4': sdlList[i]['4AJ'], \n",
        "                        '5': sdlList[i]['5AJ'], '6': sdlList[i]['6AJ'], '7': sdlList[i]['7AJ'], '8': sdlList[i]['8AJ'], \n",
        "                        '9': sdlList[i]['9AJ'], '10': sdlList[i]['10AJ'], '11': sdlList[i]['11AJ'], '12': sdlList[i]['12AJ'], \n",
        "                        '13': sdlList[i]['13AJ'], '14': sdlList[i]['14AJ'], '15': sdlList[i]['15AJ']})\n",
        "\n",
        "for i in range(len(sdlStatements)):\n",
        "  keysTemp = list(sdlStatements[i].keys())\n",
        "  for j in keysTemp:\n",
        "    if (sdlStatements[i][j]==\" \"):\n",
        "      sdlStatements[i][j] = \"No Data Recorded\"\n",
        "\n",
        "sdlObjectList = []\n",
        "for i in range(len(sdlList)):\n",
        "  sdlObjectList.append(SDL(i, sdlStatements[i], sdlList[i]['InputVideo']))"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kSIrzqV5zHMD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "8f58c9b1-fd1f-4ac4-f998-567703bc52f0"
      },
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "for i in range(len(sdlObjectList)):\n",
        "  keysTemp = list(sdlObjectList[i].statements.keys())\n",
        "  for j in (keysTemp):\n",
        "    sdlObjectList[i].getDescriptors(sdlObjectList[i].statements[j], j)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "N_Jmbn68zHML",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b64e23f1-3cfd-4598-8882-fa8ebb7f6241"
      },
      "source": [
        "examples = [1,5730,1999] \n",
        "\n",
        "for example in examples:\n",
        "    print('Object %i: '%(example))\n",
        "    print(\"Actors: \")\n",
        "    print(sdlObjectList[example].statements)\n",
        "\n",
        "    for a in range(len(sdlObjectList[example].actors)):\n",
        "      actorsIndex = str(a+1)\n",
        "      for j in range(len(sdlObjectList[example].actors[actorsIndex])):\n",
        "        print('Time segment:', actorsIndex, \",  %s: %s\"%(sdlObjectList[example].actors[actorsIndex][j].description,sdlObjectList[example].actors[actorsIndex][j].action))\n",
        "    print('Scene: ', sdlObjectList[example].scene)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Object 1: \n",
            "Actors: \n",
            "{'1': 'The car is stopped. The car is at an intersection with a red light.', '2': 'The car is accelerating through the intersection. The light at the intersection has changed to green', '3': 'No Data Recorded', '4': 'No Data Recorded', '5': 'No Data Recorded', '6': 'No Data Recorded', '7': 'No Data Recorded', '8': 'No Data Recorded', '9': 'No Data Recorded', '10': 'No Data Recorded', '11': 'No Data Recorded', '12': 'No Data Recorded', '13': 'No Data Recorded', '14': 'No Data Recorded', '15': 'No Data Recorded'}\n",
            "Time segment: 1 ,  ego: stop\n",
            "Time segment: 2 ,  ego: accelerate\n",
            "Time segment: 3 ,  NaN: NaN\n",
            "Time segment: 4 ,  NaN: NaN\n",
            "Time segment: 5 ,  NaN: NaN\n",
            "Time segment: 6 ,  NaN: NaN\n",
            "Time segment: 7 ,  NaN: NaN\n",
            "Time segment: 8 ,  NaN: NaN\n",
            "Time segment: 9 ,  NaN: NaN\n",
            "Time segment: 10 ,  NaN: NaN\n",
            "Time segment: 11 ,  NaN: NaN\n",
            "Time segment: 12 ,  NaN: NaN\n",
            "Time segment: 13 ,  NaN: NaN\n",
            "Time segment: 14 ,  NaN: NaN\n",
            "Time segment: 15 ,  NaN: NaN\n",
            "Scene:  {'1': ['light'], '2': ['green light'], '3': ['NaN'], '4': ['NaN'], '5': ['NaN'], '6': ['NaN'], '7': ['NaN'], '8': ['NaN'], '9': ['NaN'], '10': ['NaN'], '11': ['NaN'], '12': ['NaN'], '13': ['NaN'], '14': ['NaN'], '15': ['NaN']}\n",
            "Object 5730: \n",
            "Actors: \n",
            "{'1': 'The car is stopped because there are cars moving along.', '2': 'The car turns right because the road was free to turn right into.', '3': 'The car is slowly maneuvering around the cars because they are slowing the car down.', '4': 'The car is driving forward slowly since the car in front has stopped.', '5': \"The car has stopped again because the car in front isn't moving.\", '6': 'No Data Recorded', '7': 'No Data Recorded', '8': 'No Data Recorded', '9': 'No Data Recorded', '10': 'No Data Recorded', '11': 'No Data Recorded', '12': 'No Data Recorded', '13': 'No Data Recorded', '14': 'No Data Recorded', '15': 'No Data Recorded'}\n",
            "Time segment: 1 ,  ego: stop\n",
            "Time segment: 1 ,  light vehicle: forward\n",
            "Time segment: 2 ,  ego: turn right\n",
            "Time segment: 3 ,  ego: \n",
            "Time segment: 3 ,  light vehicle: brake\n",
            "Time segment: 4 ,  ego: forward\n",
            "Time segment: 5 ,  ego: stop\n",
            "Time segment: 6 ,  NaN: NaN\n",
            "Time segment: 7 ,  NaN: NaN\n",
            "Time segment: 8 ,  NaN: NaN\n",
            "Time segment: 9 ,  NaN: NaN\n",
            "Time segment: 10 ,  NaN: NaN\n",
            "Time segment: 11 ,  NaN: NaN\n",
            "Time segment: 12 ,  NaN: NaN\n",
            "Time segment: 13 ,  NaN: NaN\n",
            "Time segment: 14 ,  NaN: NaN\n",
            "Time segment: 15 ,  NaN: NaN\n",
            "Scene:  {'1': [], '2': [], '3': [], '4': [], '5': [], '6': ['NaN'], '7': ['NaN'], '8': ['NaN'], '9': ['NaN'], '10': ['NaN'], '11': ['NaN'], '12': ['NaN'], '13': ['NaN'], '14': ['NaN'], '15': ['NaN']}\n",
            "Object 1999: \n",
            "Actors: \n",
            "{'1': 'The car is accelerating Because there are no cars ahead of it and the traffic lights are green.', '2': \"The car is slowing down to a complete stop Because there are cars from opposing traffic coming into its lane to go around a UPS truck that is stopped in the street and blocking the opposing traffic's lane.\", '3': \"The car remains at a complete stop As the driver allows the opposing traffic to come in its lane in order to get around the stopped UPS truck that is blocking the opposing traffic's lane.\", '4': 'The car backs up in reverse a few feet To allow the opposing traffic more space to get around the UPS truck stopped in the street.', '5': 'The car remains at a complete stop As it waits on opposing traffic to clear from its lane.', '6': \"The car accelerates slowly while moving slightly to the right and back to the left Because it is now moving forward towards the intersection where there is a red light since the last car from the opposing traffic's lane has cleared.\", '7': 'No Data Recorded', '8': 'No Data Recorded', '9': 'No Data Recorded', '10': 'No Data Recorded', '11': 'No Data Recorded', '12': 'No Data Recorded', '13': 'No Data Recorded', '14': 'No Data Recorded', '15': 'No Data Recorded'}\n",
            "Time segment: 1 ,  ego: accelerate\n",
            "Time segment: 2 ,  ego: brake\n",
            "Time segment: 2 ,  light vehicle: \n",
            "Time segment: 2 ,  traffic: forward\n",
            "Time segment: 2 ,  heavy vehicle: stop\n",
            "Time segment: 2 ,  traffic: \n",
            "Time segment: 3 ,  ego: stop\n",
            "Time segment: 3 ,  traffic: stop\n",
            "Time segment: 3 ,  heavy vehicle: stop\n",
            "Time segment: 3 ,  traffic: \n",
            "Time segment: 4 ,  ego: reverse\n",
            "Time segment: 4 ,  traffic: \n",
            "Time segment: 4 ,  heavy vehicle: stop\n",
            "Time segment: 5 ,  ego: stop\n",
            "Time segment: 5 ,  traffic: \n",
            "Time segment: 6 ,  ego: accelerate\n",
            "Time segment: 6 ,  light vehicle: \n",
            "Time segment: 7 ,  NaN: NaN\n",
            "Time segment: 8 ,  NaN: NaN\n",
            "Time segment: 9 ,  NaN: NaN\n",
            "Time segment: 10 ,  NaN: NaN\n",
            "Time segment: 11 ,  NaN: NaN\n",
            "Time segment: 12 ,  NaN: NaN\n",
            "Time segment: 13 ,  NaN: NaN\n",
            "Time segment: 14 ,  NaN: NaN\n",
            "Time segment: 15 ,  NaN: NaN\n",
            "Scene:  {'1': ['traffic lights', 'lights'], '2': [], '3': [], '4': [], '5': [], '6': ['light'], '7': ['NaN'], '8': ['NaN'], '9': ['NaN'], '10': ['NaN'], '11': ['NaN'], '12': ['NaN'], '13': ['NaN'], '14': ['NaN'], '15': ['NaN']}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "p7JZmnlC4RBN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "a68d3ca3-efb9-48c1-8946-5f88772e7761"
      },
      "source": [
        "# Count how many actors have associated actions\n",
        "actor_count = 0\n",
        "action_count = 0\n",
        "for idx in range(len(sdlObjectList)):\n",
        "    so = sdlObjectList[idx]\n",
        "    for timestep in so.actors:\n",
        "        for actor in so.actors[timestep]:\n",
        "            if actor.description == \"NaN\":\n",
        "                break\n",
        "            actor_count+=1\n",
        "            if actor.action != \"\":\n",
        "                action_count+=1\n",
        "\n",
        "print(\"There are %i actors and %i actions. Completeness: %f\"%(actor_count,action_count,action_count/actor_count))\n",
        "\n",
        "# Display the top 10 unclassified verbs\n",
        "print(\"Top 10 unclassified verbs:\")\n",
        "dd = sorted(util.debug.items(), key = lambda kv:(-len(kv[1]),kv[0]))\n",
        "cutoff = 10\n",
        "for (key,value) in dd:\n",
        "    print(\"  %s: %i\"%(key,len(value)))\n",
        "    cutoff-=1\n",
        "    if cutoff <= 0:\n",
        "        break"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 31314 actors and 28396 actions. Completeness: 0.906815\n",
            "Top 10 unclassified verbs:\n",
            "  _None: 1968\n",
            "  is: 159\n",
            "  ha: 27\n",
            "  are: 22\n",
            "  get: 21\n",
            "  take: 21\n",
            "  begin: 20\n",
            "  straight: 19\n",
            "  approach: 18\n",
            "  jam: 18\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "HNyQjtOeA8Zf"
      },
      "source": [
        "# One-hot tensor encoding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "yqkbowE6AE8_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e283cace-149e-45e9-b735-d3bfed6f6063"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "import sys\n",
        "np.set_printoptions(threshold=sys.maxsize) #print whole numpy array for debuggingg purposes\n",
        "\n",
        "\n",
        "print(tf.__version__)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ilhMWmTwMRMt",
        "colab_type": "text"
      },
      "source": [
        "![alt text](https://drive.google.com/uc?id=1BUKjTESqh-TERLFVFF2aogMLEsFMi4qM)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KnlDHsO-Kg_P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Returns a list of unique actors, actions, and scenes\n",
        "\n",
        "actors = []\n",
        "actions = []\n",
        "scenes = []\n",
        "\n",
        "# Find unique identifiers in each category\n",
        "for sdl in sdlObjectList:\n",
        "    for timestep in range(1,len(sdl.actors)+1):\n",
        "        for obj in sdl.actors[str(timestep)]:\n",
        "            if not obj.description in actors:\n",
        "                actors.append(obj.description)\n",
        "            if not obj.action in actions:\n",
        "                actions.append(obj.action)\n",
        "        for obj in sdl.scene[str(timestep)]:\n",
        "            if not obj in scenes:\n",
        "                scenes.append(obj)\n",
        "\n",
        "# Transform lists into (key,index) pairs\n",
        "actor_encoding = {}\n",
        "scene_encoding = {}\n",
        "action_encoding = {}\n",
        "for idx in range(len(actors)):\n",
        "    actor_encoding[actors[idx]] = idx\n",
        "for idx in range(len(scenes)):\n",
        "    scene_encoding[scenes[idx]] = idx\n",
        "for idx in range(len(actions)):\n",
        "    action_encoding[actions[idx]] = idx\n"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YupAjtL84Dr6",
        "colab": {}
      },
      "source": [
        "'''\n",
        "- Each sdl object has a 7x21x22 one hot encoding representing its action, actor and scene element\n",
        "- These one hot encodings are stacked on top of each other to produce a 4D tensor [examples x actor x action x scene]\n",
        "- Last element of each dimension represents an NaN value (or empty string for action)\n",
        "\n",
        "For each SDL object in sdlObjectList, 15 (7 x 21 x 22) numpy arrays are generated to represent the 15 time segments in each object\n",
        "\n",
        "'''\n",
        "actor_encoding = {'light vehicle': 0, 'heavy vehicle': 1, 'cyclist': 2, 'pedestrian': 3, 'traffic': 4, 'ego': 5, 'NaN': 6}\n",
        "\n",
        "action_encoding = {'turn': 0, 'turn left': 1, 'turn right': 3, 'merge': 4, 'accelerate': 5, 'brake': 6, 'stop': 7, \n",
        "                   'forward': 8, 'walk': 9, 'park': 10, 'drive': 11, 'reverse': 12, 'merge center': 13, 'merge left': 14, \n",
        "                   'merge right': 15, 'turn through': 16, 'merge u turn': 17, 'u-turn': 18, 'NaN': 19, '':20}\n",
        "\n",
        "scene_encoding = {'intersection': 0, 'crosswalk': 1, 'bridge': 2, 'green light': 3, 'stop sign': 4, 'yield sign': 5, 'sign': 6, \n",
        "                  'u-turn': 7, 'traffic light': 8, 'traffic signal': 9, 'turn lane': 10, 'crosswalks': 11, 'green traffic light': 12, \n",
        "                  'light': 13, 'lights': 14, 'red light': 15, 'red traffic light': 16, 'signs': 17, 'traffic lights': 18, \n",
        "                  'yellow light': 19, 'yellow traffic light': 20, 'NaN': 21}\n",
        "\n",
        "one_hot_sdlEmbedding = []\n",
        "\n",
        "examples = [3, 413]\n",
        "for example in range(len(sdlObjectList)): #loops through 6996 sdl objects in sdlObjectList\n",
        "    # Each sdl object has a 7x21x22 one hot encoding representing its action, actor and scene element\n",
        "    for a in range(len(sdlObjectList[example].actors)): #loops through 15 time segments\n",
        "      #print(\"time segments: \", len(sdlObjectList[example].actors))\n",
        "      #print(a)\n",
        "      indices = np.zeros((7,21,22))\n",
        "      actorsIndex = str(a+1)\n",
        "      actor_list = []\n",
        "      action_list = []\n",
        "      scene_list = []\n",
        "      for j in range(len(sdlObjectList[example].actors[actorsIndex])):\n",
        "        actor_list.append(sdlObjectList[example].actors[actorsIndex][j].description)\n",
        "        action_list.append(sdlObjectList[example].actors[actorsIndex][j].action)\n",
        "\n",
        "      scene_list.append(sdlObjectList[example].scene[actorsIndex])\n",
        "      \n",
        "      #print(\"actor list: \", actor_list)\n",
        "      #print(\"action list: \", action_list)\n",
        "      #print(\"scene list: \", scene_list)\n",
        "\n",
        "      actor_indices = []\n",
        "      action_indices = []\n",
        "      scene_indices = []\n",
        "\n",
        "\n",
        "      if(len(actor_list) != len(action_list)):\n",
        "        print(\"Actor and action list don't match up, this may cause 1 to 1 actor to action correspondence errors\")\n",
        "        break\n",
        "      \n",
        "      for a_index in actor_list:\n",
        "        actor_indices.append(actor_encoding[a_index])\n",
        "\n",
        "      for act_index in action_list:\n",
        "        action_indices.append(action_encoding[act_index])\n",
        "\n",
        "      if( ((len(scene_list)) > 0) and scene_list[0] != 'NaN'):\n",
        "        for i in scene_list:\n",
        "          for j in i:\n",
        "            scene_indices.append(scene_encoding[j])\n",
        "      else:\n",
        "        scene_indices.clear()\n",
        "        scene_indices.append(21)\n",
        "\n",
        "      if(len(actor_indices) != len(action_indices)):\n",
        "        print(\"make sure each actor is matched up with an action\")\n",
        "        break\n",
        "      # if each sdl has an actor paired with each action, how do we account for multiple scene elements\n",
        "      #print(\"actor indices: \", actor_indices)\n",
        "      #print(\"action indices: \", action_indices)\n",
        "      #print(\"scene indices: \", scene_indices)\n",
        "\n",
        "      if(len(scene_indices) > 0):\n",
        "        for scene_index in scene_indices:\n",
        "          for i, actor_index in enumerate(actor_indices):\n",
        "            # since there is a one to one mapping between actor and actions, we can use the same index\n",
        "            action_index = action_indices[i]\n",
        "            #print(\"for\")\n",
        "            #print(\"actor index: \", actor_index, \" action index: \", action_index, \" scene_index: \", scene_index)\n",
        "            indices[actor_index][action_index][scene_index] = 1.0\n",
        "      else:\n",
        "        scene_index = 21\n",
        "        for i, actor_index in enumerate(actor_indices):\n",
        "          action_index = action_indices[i]\n",
        "          #print(\"else\")\n",
        "          #print(\"actor index: \", actor_index, \" action index: \", action_index, \" scene_index: \", scene_index)\n",
        "          indices[actor_index][action_index][scene_index] = 1.0\n",
        "\n",
        "      one_hot_sdlEmbedding.append(tf.convert_to_tensor(indices))\n",
        "assert len(one_hot_sdlEmbedding) == 104940, \"length of one_hot_sdlEmbedding should be 104940\""
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AOT3PIt4x-6q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "706c4106-43b8-4fef-e21a-75eb397cdee6"
      },
      "source": [
        "sparse_tensor_list = []\n",
        "for item in one_hot_sdlEmbedding:\n",
        "  item = tf.expand_dims(item, axis=0)\n",
        "  sparse_tensor_list.append(tf.sparse.from_dense(item))\n",
        "\n",
        "assert len(sparse_tensor_list) == 104940, \"length of sparse_tensor list should be 104940\"\n",
        "sdl_encoding= tf.sparse.concat(0, sparse_tensor_list)\n",
        "sdl_encoding.shape"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([104940, 7, 21, 22])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jf4nSHOgyg9Z",
        "colab_type": "text"
      },
      "source": [
        "# SDL ID Generation Based Loosely on https://oas.voyage.auto/scenarios/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "28dPWGqNLhSB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "Format of SDL embedding: Actor:Action, Actor:Action...-SceneElement\n",
        "'''\n",
        "actor_encoding = {'light vehicle': 0, 'heavy vehicle': 1, 'cyclist': 2, 'pedestrian': 3, 'traffic': 4, 'ego': 5, 'NaN': 6}\n",
        "\n",
        "action_encoding = {'turn': 0, 'turn left': 1, 'turn right': 3, 'merge': 4, 'accelerate': 5, 'brake': 6, 'stop': 7, \n",
        "                   'forward': 8, 'walk': 9, 'park': 10, 'drive': 11, 'reverse': 12, 'merge center': 13, 'merge left': 14, \n",
        "                   'merge right': 15, 'turn through': 16, 'merge u turn': 17, 'u-turn': 18, 'NaN': 19, '':20}\n",
        "\n",
        "scene_encoding = {'intersection': 0, 'crosswalk': 1, 'bridge': 2, 'green light': 3, 'stop sign': 4, 'yield sign': 5, 'sign': 6, \n",
        "                  'u-turn': 7, 'traffic light': 8, 'traffic signal': 9, 'turn lane': 10, 'crosswalks': 11, 'green traffic light': 12, \n",
        "                  'light': 13, 'lights': 14, 'red light': 15, 'red traffic light': 16, 'signs': 17, 'traffic lights': 18, \n",
        "                  'yellow light': 19, 'yellow traffic light': 20, 'NaN': 21}\n",
        "scene_encoding_keysList = list(scene_encoding.keys())\n",
        "scene_encoding_valuesList = list(scene_encoding.values())\n",
        "sdl_ids = []\n",
        "\n",
        "for example in range(len(sdlObjectList)): #loops through 6996 sdl objects in sdlObjectList\n",
        "    # Each sdl object has a 7x21x22 one hot encoding representing its action, actor and scene element\n",
        "    for a in range(len(sdlObjectList[example].actors)): #loops through 15 time segments\n",
        "      #print(\"time segments: \", len(sdlObjectList[example].actors))\n",
        "      #print(a)\n",
        "      sdl_id = []\n",
        "      actorsIndex = str(a+1)\n",
        "      actor_list = []\n",
        "      action_list = []\n",
        "      scene_list = []\n",
        "      for j in range(len(sdlObjectList[example].actors[actorsIndex])):\n",
        "        actor_list.append(sdlObjectList[example].actors[actorsIndex][j].description)\n",
        "        action_list.append(sdlObjectList[example].actors[actorsIndex][j].action)\n",
        "\n",
        "      scene_list.append(sdlObjectList[example].scene[actorsIndex])\n",
        "      \n",
        "      #print(\"actor list: \", actor_list)\n",
        "      #rint(\"action list: \", action_list)\n",
        "      #print(\"scene list: \", scene_list)\n",
        "\n",
        "      actor_indices = []\n",
        "      action_indices = []\n",
        "      scene_indices = []\n",
        "\n",
        "\n",
        "      if(len(actor_list) != len(action_list)):\n",
        "        print(\"Actor and action list don't match up, this may cause 1 to 1 actor to action correspondence errors\")\n",
        "        break\n",
        "      \n",
        "      for a_index in actor_list:\n",
        "        actor_indices.append(actor_encoding[a_index])\n",
        "\n",
        "      for act_index in action_list:\n",
        "        action_indices.append(action_encoding[act_index])\n",
        "\n",
        "      if( ((len(scene_list)) > 0) and scene_list[0] != 'NaN'):\n",
        "        for i in scene_list:\n",
        "          for j in i:\n",
        "            scene_indices.append(scene_encoding[j])\n",
        "      else:\n",
        "        scene_indices.clear()\n",
        "        scene_indices.append(21)\n",
        "\n",
        "      if(len(actor_indices) != len(action_indices)):\n",
        "        print(\"make sure each actor is matched up with an action\")\n",
        "        break\n",
        "      # if each sdl has an actor paired with each action, how do we account for multiple scene elements\n",
        "      #print(\"actor indices: \", actor_indices)\n",
        "      #print(\"action indices: \", action_indices)\n",
        "      #print(\"scene indices: \", scene_indices)\n",
        "\n",
        "      if(len(scene_indices) > 0):\n",
        "        for i, actor in enumerate(actor_list):\n",
        "        # since there is a one to one mapping between actor and actions, we can use the same index\n",
        "            sdl_id.append(\",\")\n",
        "            sdl_id.append(actor)\n",
        "            sdl_id.append(\":\") \n",
        "            sdl_id.append(action_list[i])\n",
        "            sdl_id.append(\"-\")\n",
        "        for j in scene_indices:\n",
        "            sdl_id.append(scene_encoding_keysList[scene_encoding_valuesList.index(j)])\n",
        "        sdl_id.append(\".\")\n",
        "\n",
        "      else:\n",
        "        for i, actor in enumerate(actor_list):\n",
        "            sdl_id.append(\",\")\n",
        "            sdl_id.append(actor)\n",
        "            sdl_id.append(\":\") \n",
        "            sdl_id.append(action_list[i])\n",
        "            #sdl_id.append(\"-\")\n",
        "        for j in scene_indices:\n",
        "            sdl_id.append(scene_encoding_keysList[scene_encoding_valuesList.index(j)])\n",
        "        sdl_id.append(\".\")\n",
        "\n",
        "      sdl_id.pop(0)\n",
        "      sdl_ids.append(\"\".join(sdl_id))\n",
        "assert len(sdl_ids) == 104940, \"length of sdl_ids should be 104940\""
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-7IvUYkM8j7m",
        "colab_type": "text"
      },
      "source": [
        "# Doc2Vec"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8zAc4TKtImWl",
        "colab_type": "text"
      },
      "source": [
        "Rough implementation of Doc2Vec for bddx dataset, and a simple distance measurement between two \"similar sentences\" and our corresponding sdl_embedding. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4xnHuQiK9fex",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# prep list of sentences\n",
        "bddx_statements = []\n",
        "for i in range(len(sdlList)):\n",
        "  bddx_statements.append(sdlList[i]['1AJ'])\n",
        "  bddx_statements.append(sdlList[i]['2AJ'])\n",
        "  bddx_statements.append(sdlList[i]['3AJ'])\n",
        "  bddx_statements.append(sdlList[i]['4AJ'])\n",
        "  bddx_statements.append(sdlList[i]['5AJ'])\n",
        "  bddx_statements.append(sdlList[i]['6AJ'])\n",
        "  bddx_statements.append(sdlList[i]['7AJ'])\n",
        "  bddx_statements.append(sdlList[i]['8AJ'])\n",
        "  bddx_statements.append(sdlList[i]['9AJ'])\n",
        "  bddx_statements.append(sdlList[i]['10AJ'])\n",
        "  bddx_statements.append(sdlList[i]['11AJ'])\n",
        "  bddx_statements.append(sdlList[i]['12AJ'])\n",
        "  bddx_statements.append(sdlList[i]['13AJ'])\n",
        "  bddx_statements.append(sdlList[i]['14AJ'])\n",
        "  bddx_statements.append(sdlList[i]['15AJ'])\n",
        "assert len(bddx_statements) == 104940, \"length of bddx_statements should be 104940\""
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ua288SGSAKG1",
        "colab_type": "text"
      },
      "source": [
        "https://medium.com/@mishra.thedeepak/doc2vec-simple-implementation-example-df2afbbfbad5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aR2Ql1Kk1RYN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bddx_statements = [\"nan\" if (x == \"\" or x==\" \") else x for x in bddx_statements]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ci3vzG_eAGrs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Import all the dependencies\n",
        "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
        "from nltk.tokenize import word_tokenize"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UPDcV-bTAMtp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tagged_data = [TaggedDocument(words=word_tokenize(_d.lower()), tags=[str(i)]) for i, _d in enumerate(bddx_statements)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vpnm-MzxAOmq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 819
        },
        "outputId": "4b1db85b-9ff0-4bc3-b055-e834e5f1d582"
      },
      "source": [
        "max_epochs = 40\n",
        "vec_size = 20\n",
        "alpha = 0.025\n",
        "\n",
        "model = Doc2Vec(size=vec_size,\n",
        "                alpha=alpha, \n",
        "                min_alpha=0.00025,\n",
        "                min_count=1,\n",
        "                dm =1)\n",
        "  \n",
        "model.build_vocab(tagged_data)\n",
        "\n",
        "for epoch in range(max_epochs):\n",
        "    print('iteration {0}'.format(epoch))\n",
        "    model.train(tagged_data,\n",
        "                total_examples=model.corpus_count,\n",
        "                epochs=model.iter)\n",
        "    # decrease the learning rate\n",
        "    model.alpha -= 0.0002\n",
        "    # fix the learning rate, no decay\n",
        "    model.min_alpha = model.alpha\n",
        "\n",
        "model.save(\"d2v.model\")\n",
        "print(\"Model Saved\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/models/doc2vec.py:570: UserWarning: The parameter `size` is deprecated, will be removed in 4.0.0, use `vector_size` instead.\n",
            "  warnings.warn(\"The parameter `size` is deprecated, will be removed in 4.0.0, use `vector_size` instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "iteration 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:17: DeprecationWarning: Call to deprecated `iter` (Attribute will be removed in 4.0.0, use self.epochs instead).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "iteration 1\n",
            "iteration 2\n",
            "iteration 3\n",
            "iteration 4\n",
            "iteration 5\n",
            "iteration 6\n",
            "iteration 7\n",
            "iteration 8\n",
            "iteration 9\n",
            "iteration 10\n",
            "iteration 11\n",
            "iteration 12\n",
            "iteration 13\n",
            "iteration 14\n",
            "iteration 15\n",
            "iteration 16\n",
            "iteration 17\n",
            "iteration 18\n",
            "iteration 19\n",
            "iteration 20\n",
            "iteration 21\n",
            "iteration 22\n",
            "iteration 23\n",
            "iteration 24\n",
            "iteration 25\n",
            "iteration 26\n",
            "iteration 27\n",
            "iteration 28\n",
            "iteration 29\n",
            "iteration 30\n",
            "iteration 31\n",
            "iteration 32\n",
            "iteration 33\n",
            "iteration 34\n",
            "iteration 35\n",
            "iteration 36\n",
            "iteration 37\n",
            "iteration 38\n",
            "iteration 39\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:253: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model Saved\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2CVb3vBPATBf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "640c46e7-02d4-48b1-ae75-bea4eb3d9e4d"
      },
      "source": [
        "from gensim.models.doc2vec import Doc2Vec\n",
        "\n",
        "model= Doc2Vec.load(\"d2v.model\")\n",
        "\n",
        "assert len(model.docvecs) == 104940, \"Number of vectors, should be 104940"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of vectors, should be 104940 == sentences in dataset == size of sdl embedding:  104940\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:253: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d-kudrc00OdW",
        "colab_type": "text"
      },
      "source": [
        "# Doc2Vec for Open Autonomous Vehicle Embedding \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r5_GJZ2k0k-q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Import all the dependencies\n",
        "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
        "from nltk.tokenize import word_tokenize"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vonJnLdA0njm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tagged_data = [TaggedDocument(words=word_tokenize(_d.lower()), tags=[str(i)]) for i, _d in enumerate(sdl_ids)]"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wIkejlw80oAi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 819
        },
        "outputId": "279ae549-71d5-4a8f-e5fe-1e4a31caf733"
      },
      "source": [
        "max_epochs = 150\n",
        "vec_size = 100\n",
        "alpha = 0.0025\n",
        "\n",
        "model = Doc2Vec(size=vec_size,\n",
        "                alpha=alpha, \n",
        "                min_alpha=0.00025,\n",
        "                min_count=1,\n",
        "                dm =1)\n",
        "  \n",
        "model.build_vocab(tagged_data)\n",
        "\n",
        "for epoch in range(max_epochs):\n",
        "    print('iteration {0}'.format(epoch))\n",
        "    model.train(tagged_data,\n",
        "                total_examples=model.corpus_count,\n",
        "                epochs=model.iter)\n",
        "    # decrease the learning rate\n",
        "    model.alpha -= 0.0002\n",
        "    # fix the learning rate, no decay\n",
        "    model.min_alpha = model.alpha\n",
        "\n",
        "model.save(\"d2v_sdl_ids.model\")\n",
        "print(\"Model Saved\")"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/models/doc2vec.py:570: UserWarning: The parameter `size` is deprecated, will be removed in 4.0.0, use `vector_size` instead.\n",
            "  warnings.warn(\"The parameter `size` is deprecated, will be removed in 4.0.0, use `vector_size` instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "iteration 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:17: DeprecationWarning: Call to deprecated `iter` (Attribute will be removed in 4.0.0, use self.epochs instead).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "iteration 1\n",
            "iteration 2\n",
            "iteration 3\n",
            "iteration 4\n",
            "iteration 5\n",
            "iteration 6\n",
            "iteration 7\n",
            "iteration 8\n",
            "iteration 9\n",
            "iteration 10\n",
            "iteration 11\n",
            "iteration 12\n",
            "iteration 13\n",
            "iteration 14\n",
            "iteration 15\n",
            "iteration 16\n",
            "iteration 17\n",
            "iteration 18\n",
            "iteration 19\n",
            "iteration 20\n",
            "iteration 21\n",
            "iteration 22\n",
            "iteration 23\n",
            "iteration 24\n",
            "iteration 25\n",
            "iteration 26\n",
            "iteration 27\n",
            "iteration 28\n",
            "iteration 29\n",
            "iteration 30\n",
            "iteration 31\n",
            "iteration 32\n",
            "iteration 33\n",
            "iteration 34\n",
            "iteration 35\n",
            "iteration 36\n",
            "iteration 37\n",
            "iteration 38\n",
            "iteration 39\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:253: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model Saved\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_nk2Vood0s7P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "78d0717c-322a-4d05-8946-09513e9f0ed8"
      },
      "source": [
        "from gensim.models.doc2vec import Doc2Vec\n",
        "\n",
        "model_sdl_ids = Doc2Vec.load(\"d2v_sdl_ids.model\")\n",
        "assert len(model_sdl_ids.docvecs) == 104940, \"Number of vectors, should be 104940\""
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:253: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5zJaTSCA1W-4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "d9e3ed90-4713-4284-f9c8-5d2ca0ff7448"
      },
      "source": [
        "# 1. prove that doc2vec model can generate similar SDL objects\n",
        "# 2. show that similar SDLs have similar vector distances\n",
        "# 3. generate a list of similar SDLs for a single reference SDL \n",
        "# 4. generate a list of similar SDLs to the same reference SDL using the previous doc2vec model\n",
        "# 5. compare the two generated lists for similar returned SDLs and the extra ones returned by our SDL model \n",
        "\n",
        "from scipy import spatial\n",
        "first_text = sdl_ids[6195]\n",
        "second_text = sdl_ids[45]\n",
        "print(sdl_ids[30])\n",
        "print('first text: ', first_text)\n",
        "print('second text: ', second_text)\n",
        "\n",
        "vec1 = model.docvecs[6195]\n",
        "vec2 = model.docvecs[30]\n",
        "\n",
        "similairty = spatial.distance.cosine(vec1, vec2)\n",
        "euclidean = spatial.distance.euclidean(vec1, vec2)\n",
        "print(euclidean)\n",
        "print(similairty)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ego:accelerate-,traffic:forward-green light.\n",
            "first text:  ego:forward,traffic:forward.\n",
            "second text:  ego:forward,traffic:forward.\n",
            "3.860210657119751\n",
            "0.8689534217119217\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BhjNEbcDRqZG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "f4d6a2ca-4648-426f-e09c-fc26da87eb96"
      },
      "source": [
        "print(sdl_ids[50])\n",
        "print(bddx_statements[50])\n",
        "bddx_statements_condensed = list(filter(lambda a: a != \" \", bddx_statements))\n",
        "print(len(bddx_statements_condensed))\n",
        "sdl_ids_condensed = list(filter(lambda a: a != \"NaN:NaN-NaN.\", sdl_ids))\n",
        "print(len(sdl_ids_condensed))\n"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NaN:NaN-NaN.\n",
            " \n",
            "26539\n",
            "26539\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kWpPV1CIIYSJ",
        "colab_type": "text"
      },
      "source": [
        "# Experiment for Open Autonomous Safety SDLs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t_jOGkkIKw6H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# https://stackoverflow.com/questions/50861237/is-there-an-alternative-to-difflib-get-close-matches-that-returns-indexes-l\n",
        "import difflib\n",
        "from heapq import nlargest as _nlargest\n",
        "\n",
        "def get_close_matches_indexes(word, possibilities, n=3, cutoff=0.6):\n",
        "    \"\"\"Use SequenceMatcher to return a list of the indexes of the best \n",
        "    \"good enough\" matches. word is a sequence for which close matches \n",
        "    are desired (typically a string).\n",
        "    possibilities is a list of sequences against which to match word\n",
        "    (typically a list of strings).\n",
        "    Optional arg n (default 3) is the maximum number of close matches to\n",
        "    return.  n must be > 0.\n",
        "    Optional arg cutoff (default 0.6) is a float in [0, 1].  Possibilities\n",
        "    that don't score at least that similar to word are ignored.\n",
        "    \"\"\"\n",
        "\n",
        "    if not n >  0:\n",
        "        raise ValueError(\"n must be > 0: %r\" % (n,))\n",
        "    if not 0.0 <= cutoff <= 1.0:\n",
        "        raise ValueError(\"cutoff must be in [0.0, 1.0]: %r\" % (cutoff,))\n",
        "    result = []\n",
        "    s = difflib.SequenceMatcher()\n",
        "    s.set_seq2(word)\n",
        "    for idx, x in enumerate(possibilities):\n",
        "        s.set_seq1(x)\n",
        "        if s.real_quick_ratio() >= cutoff and \\\n",
        "           s.quick_ratio() >= cutoff and \\\n",
        "           s.ratio() >= cutoff:\n",
        "            result.append((s.ratio(), idx))\n",
        "\n",
        "    # Move the best scorers to head of list\n",
        "    result = _nlargest(n, result)\n",
        "\n",
        "    # Strip scores for the best n matches\n",
        "    return [x for score, x in result]"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wRjRrtb6SpU_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "scores = []\n",
        "for index, id in enumerate(sdl_ids_condensed[:5000]):\n",
        "    print(\"index: \", index)\n",
        "    sdl_ids_similar = set(get_close_matches_indexes(id, sdl_ids_condensed))\n",
        "    bddx_statements_similar = set(get_close_matches_indexes(bddx_statements_condensed[index], bddx_statements_condensed))\n",
        "    intersection = list(sdl_ids_similar.intersection(bddx_statements_similar))\n",
        "    count = len(intersection) \n",
        "    scores.append(count)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rvZKA17KK9IL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "4b69c258-5d44-45a5-9280-bbc7438b62cc"
      },
      "source": [
        "scores = []\n",
        "for index, id in enumerate(sdl_ids_condensed):\n",
        "    print(\"index: \", index)\n",
        "    sdl_ids_similar = set(get_close_matches_indexes(id, sdl_ids_condensed))\n",
        "    bddx_statements_similar = set(get_close_matches_indexes(bddx_statements_condensed[index], bddx_statements_condensed))\n",
        "    intersection = list(sdl_ids_similar.intersection(bddx_statements_similar))\n",
        "    count = len(intersection) \n",
        "    scores.append(count)"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "index:  0\n",
            "index:  1\n",
            "index:  2\n",
            "index:  3\n",
            "index:  4\n",
            "index:  5\n",
            "index:  6\n",
            "index:  7\n",
            "index:  8\n",
            "index:  9\n",
            "index:  10\n",
            "index:  11\n",
            "index:  12\n",
            "index:  13\n",
            "index:  14\n",
            "index:  15\n",
            "index:  16\n",
            "index:  17\n",
            "index:  18\n",
            "index:  19\n",
            "index:  20\n",
            "index:  21\n",
            "index:  22\n",
            "index:  23\n",
            "index:  24\n",
            "index:  25\n",
            "index:  26\n",
            "index:  27\n",
            "index:  28\n",
            "index:  29\n",
            "index:  30\n",
            "index:  31\n",
            "index:  32\n",
            "index:  33\n",
            "index:  34\n",
            "index:  35\n",
            "index:  36\n",
            "index:  37\n",
            "index:  38\n",
            "index:  39\n",
            "index:  40\n",
            "index:  41\n",
            "index:  42\n",
            "index:  43\n",
            "index:  44\n",
            "index:  45\n",
            "index:  46\n",
            "index:  47\n",
            "index:  48\n",
            "index:  49\n",
            "index:  50\n",
            "index:  51\n",
            "index:  52\n",
            "index:  53\n",
            "index:  54\n",
            "index:  55\n",
            "index:  56\n",
            "index:  57\n",
            "index:  58\n",
            "index:  59\n",
            "index:  60\n",
            "index:  61\n",
            "index:  62\n",
            "index:  63\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-81-f666293a0f3a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"index: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0msdl_ids_similar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_close_matches_indexes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msdl_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mbddx_statements_similar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_close_matches_indexes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbddx_statements\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbddx_statements\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mintersection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msdl_ids_similar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintersection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbddx_statements_similar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mintersection\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-76-5eed5a5ce5fa>\u001b[0m in \u001b[0;36mget_close_matches_indexes\u001b[0;34m(word, possibilities, n, cutoff)\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibilities\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_seq1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreal_quick_ratio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mcutoff\u001b[0m \u001b[0;32mand\u001b[0m            \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquick_ratio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mcutoff\u001b[0m \u001b[0;32mand\u001b[0m            \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mratio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mcutoff\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m             \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mratio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/difflib.py\u001b[0m in \u001b[0;36mratio\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    642\u001b[0m         \"\"\"\n\u001b[1;32m    643\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 644\u001b[0;31m         \u001b[0mmatches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtriple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtriple\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_matching_blocks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    645\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_calculate_ratio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/difflib.py\u001b[0m in \u001b[0;36mget_matching_blocks\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    477\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mqueue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    478\u001b[0m             \u001b[0malo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mahi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbhi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 479\u001b[0;31m             \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_longest_match\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mahi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbhi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    480\u001b[0m             \u001b[0;31m# a[alo:i] vs b[blo:j] unknown\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m             \u001b[0;31m# a[i:i+k] same as b[j:j+k]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/difflib.py\u001b[0m in \u001b[0;36mfind_longest_match\u001b[0;34m(self, alo, ahi, blo, bhi)\u001b[0m\n\u001b[1;32m    402\u001b[0m             \u001b[0mj2lenget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mj2len\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m             \u001b[0mnewj2len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 404\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mb2j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnothing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    405\u001b[0m                 \u001b[0;31m# a[i] matches b[j]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mj\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mblo\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u7x9_gsbDAgv",
        "colab_type": "text"
      },
      "source": [
        "# Experiment 1: SDL Validation by Visual Inspection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ebHCReCOU-cs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "852468b3-0217-413b-fa76-5fbb1021f77b"
      },
      "source": [
        "# sdl 3: one_hot_sdlEmbedding[46] = one_hot_sdlEmbedding[(15*3)] ----> 15 time segments per sdl + 1st time segment in sdl object 3\n",
        "# sdl 413: one_hot_sdlEmbedding[6195] = one_hot_sdlEmbedding[(15*413)]----> 15 time segments per sdl + 1st time segment in sdl object 413\n",
        "# sdl 571: one_hot_sdlEmbedding[8568] = one_hot_sdlEmbedding[(15*571)+2]----> 15 time segments per sdl + 3rd time segment in sdl object 571\n",
        "examples = [3,413,571] \n",
        "\n",
        "for example in examples:\n",
        "    print('Object %i: '%(example))\n",
        "    print(\"Actors: \")\n",
        "    print(sdlObjectList[example].statements)\n",
        "\n",
        "    for a in range(len(sdlObjectList[example].actors)):\n",
        "      actorsIndex = str(a+1)\n",
        "      for j in range(len(sdlObjectList[example].actors[actorsIndex])):\n",
        "        print('Time segment:', actorsIndex, \",  %s: %s\"%(sdlObjectList[example].actors[actorsIndex][j].description,sdlObjectList[example].actors[actorsIndex][j].action))\n",
        "    print('Scene: ', sdlObjectList[example].scene)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Object 3: \n",
            "Actors: \n",
            "{'1': 'The car is driving forward as traffic flows freely.', '2': 'The car merges into the lane to its left to get around a slower car in front of it.', '3': 'The car drives at a normal speed as traffic moves freely.', '4': \"The car slows and veers slightly right due to a car in the neighboring lane entering the car's lane.\", '5': 'The car drives forward as there are no nearby cars in its lane.', '6': 'No Data Recorded', '7': 'No Data Recorded', '8': 'No Data Recorded', '9': 'No Data Recorded', '10': 'No Data Recorded', '11': 'No Data Recorded', '12': 'No Data Recorded', '13': 'No Data Recorded', '14': 'No Data Recorded', '15': 'No Data Recorded'}\n",
            "Time segment: 1 ,  ego: forward\n",
            "Time segment: 1 ,  traffic: forward\n",
            "Time segment: 2 ,  ego: merge left\n",
            "Time segment: 2 ,  light vehicle: \n",
            "Time segment: 4 ,  ego: brake\n",
            "Time segment: 4 ,  light vehicle: merge\n",
            "Time segment: 5 ,  ego: forward\n",
            "Time segment: 6 ,  NaN: NaN\n",
            "Time segment: 7 ,  NaN: NaN\n",
            "Time segment: 8 ,  NaN: NaN\n",
            "Time segment: 9 ,  NaN: NaN\n",
            "Time segment: 10 ,  NaN: NaN\n",
            "Time segment: 11 ,  NaN: NaN\n",
            "Time segment: 12 ,  NaN: NaN\n",
            "Time segment: 13 ,  NaN: NaN\n",
            "Time segment: 14 ,  NaN: NaN\n",
            "Time segment: 15 ,  NaN: NaN\n",
            "Scene:  {'1': [], '2': [], '3': [], '4': [], '5': [], '6': ['NaN'], '7': ['NaN'], '8': ['NaN'], '9': ['NaN'], '10': ['NaN'], '11': ['NaN'], '12': ['NaN'], '13': ['NaN'], '14': ['NaN'], '15': ['NaN']}\n",
            "Object 413: \n",
            "Actors: \n",
            "{'1': 'The car is driving forward as traffic flows freely.', '2': 'The car slows to a stop due to a red light.', '3': 'No Data Recorded', '4': 'No Data Recorded', '5': 'No Data Recorded', '6': 'No Data Recorded', '7': 'No Data Recorded', '8': 'No Data Recorded', '9': 'No Data Recorded', '10': 'No Data Recorded', '11': 'No Data Recorded', '12': 'No Data Recorded', '13': 'No Data Recorded', '14': 'No Data Recorded', '15': 'No Data Recorded'}\n",
            "Time segment: 1 ,  ego: forward\n",
            "Time segment: 1 ,  traffic: forward\n",
            "Time segment: 2 ,  ego: brake\n",
            "Time segment: 3 ,  NaN: NaN\n",
            "Time segment: 4 ,  NaN: NaN\n",
            "Time segment: 5 ,  NaN: NaN\n",
            "Time segment: 6 ,  NaN: NaN\n",
            "Time segment: 7 ,  NaN: NaN\n",
            "Time segment: 8 ,  NaN: NaN\n",
            "Time segment: 9 ,  NaN: NaN\n",
            "Time segment: 10 ,  NaN: NaN\n",
            "Time segment: 11 ,  NaN: NaN\n",
            "Time segment: 12 ,  NaN: NaN\n",
            "Time segment: 13 ,  NaN: NaN\n",
            "Time segment: 14 ,  NaN: NaN\n",
            "Time segment: 15 ,  NaN: NaN\n",
            "Scene:  {'1': [], '2': ['light'], '3': ['NaN'], '4': ['NaN'], '5': ['NaN'], '6': ['NaN'], '7': ['NaN'], '8': ['NaN'], '9': ['NaN'], '10': ['NaN'], '11': ['NaN'], '12': ['NaN'], '13': ['NaN'], '14': ['NaN'], '15': ['NaN']}\n",
            "Object 571: \n",
            "Actors: \n",
            "{'1': 'The car is driving forward because its lane is free of traffic.', '2': 'The car is slowing down as the light is red.', '3': 'The car is driving forward as traffic flows freely.', '4': 'No Data Recorded', '5': 'No Data Recorded', '6': 'No Data Recorded', '7': 'No Data Recorded', '8': 'No Data Recorded', '9': 'No Data Recorded', '10': 'No Data Recorded', '11': 'No Data Recorded', '12': 'No Data Recorded', '13': 'No Data Recorded', '14': 'No Data Recorded', '15': 'No Data Recorded'}\n",
            "Time segment: 1 ,  ego: forward\n",
            "Time segment: 2 ,  ego: brake\n",
            "Time segment: 3 ,  ego: forward\n",
            "Time segment: 3 ,  traffic: forward\n",
            "Time segment: 4 ,  NaN: NaN\n",
            "Time segment: 5 ,  NaN: NaN\n",
            "Time segment: 6 ,  NaN: NaN\n",
            "Time segment: 7 ,  NaN: NaN\n",
            "Time segment: 8 ,  NaN: NaN\n",
            "Time segment: 9 ,  NaN: NaN\n",
            "Time segment: 10 ,  NaN: NaN\n",
            "Time segment: 11 ,  NaN: NaN\n",
            "Time segment: 12 ,  NaN: NaN\n",
            "Time segment: 13 ,  NaN: NaN\n",
            "Time segment: 14 ,  NaN: NaN\n",
            "Time segment: 15 ,  NaN: NaN\n",
            "Scene:  {'1': [], '2': ['red light'], '3': [], '4': ['NaN'], '5': ['NaN'], '6': ['NaN'], '7': ['NaN'], '8': ['NaN'], '9': ['NaN'], '10': ['NaN'], '11': ['NaN'], '12': ['NaN'], '13': ['NaN'], '14': ['NaN'], '15': ['NaN']}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rPL2aQqLEGPp",
        "colab_type": "text"
      },
      "source": [
        "## Experiment 1: MSE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rbSPjnGPEAd1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "A = one_hot_sdlEmbedding[45].numpy()\n",
        "B = one_hot_sdlEmbedding[6195].numpy()\n",
        "C = one_hot_sdlEmbedding[8567].numpy()\n",
        "\n",
        "diff1 = one_hot_sdlEmbedding[61].numpy()\n",
        "\n",
        "\n",
        "mseAB = (np.square(A - B)).mean(axis=None)\n",
        "mseBC = (np.square(B - C)).mean(axis=None)\n",
        "mseAC = (np.square(A - C)).mean(axis=None)\n",
        "\n",
        "mseDiffA = (np.square(A - diff1)).mean(axis=None)\n",
        "mseDiffB = (np.square(B - diff1)).mean(axis=None)\n",
        "mseDiffC = (np.square(C - diff1)).mean(axis=None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eLhi96rXiEm5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "99752ead-a986-402c-f07d-dee4406cc125"
      },
      "source": [
        "print(bddx_statements[45])\n",
        "print(bddx_statements[6195])\n",
        "print(bddx_statements[8567])\n",
        "print(\"different statement: \", bddx_statements[61])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The car is driving forward as traffic flows freely.\n",
            "The car is driving forward as traffic flows freely.\n",
            "The car is driving forward as traffic flows freely.\n",
            "different statement:  The car is accelerating as the light turned green.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p6L4XurcGdtb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "52b4523e-67e2-444f-c419-cd1e054d68a2"
      },
      "source": [
        "print(\"MSE between SDL object 3 and 413: \", mseAB)\n",
        "print(\"MSE between SDL object 413 and 571: \", mseBC)\n",
        "print(\"MSE between SDL object 571 and 3: \", mseAC)\n",
        "\n",
        "print(\"MSE between SDL object 3 and diff: \", mseDiffA)\n",
        "print(\"MSE between SDL object 413 and diff: \", mseDiffB)\n",
        "print(\"MSE between SDL object 571 and diff: \", mseDiffC)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MSE between SDL object 3 and 413:  0.0\n",
            "MSE between SDL object 413 and 571:  0.0\n",
            "MSE between SDL object 571 and 3:  0.0\n",
            "MSE between SDL object 3 and diff:  0.0009276437847866419\n",
            "MSE between SDL object 413 and diff:  0.0009276437847866419\n",
            "MSE between SDL object 571 and diff:  0.0009276437847866419\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aJ6jkgM9EL3h",
        "colab_type": "text"
      },
      "source": [
        "## Experiment 1: Doc2Vec Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eoXKFwYqFWuz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "outputId": "ec5b24d2-0bee-4d10-e89d-be2cec581ec7"
      },
      "source": [
        "# finds top 10 most similar sentences to test data \n",
        "test = \"The car is driving forward as traffic flows freely.\".split(\" \")  \n",
        "\n",
        "ivec = model.infer_vector(doc_words=test, steps=150, alpha=0.00025)\n",
        "model.docvecs.most_similar(positive=[ivec], topn=10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('12933', 0.855712890625),\n",
              " ('35611', 0.8320037722587585),\n",
              " ('50312', 0.8197561502456665),\n",
              " ('35685', 0.8095692992210388),\n",
              " ('30840', 0.8091429471969604),\n",
              " ('101418', 0.808503270149231),\n",
              " ('42153', 0.8056596517562866),\n",
              " ('35402', 0.8028759956359863),\n",
              " ('71176', 0.8016964197158813),\n",
              " ('68010', 0.7989912033081055)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 253
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VUoqaLgFTts-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "2da1c6f6-2fb1-456f-db49-d0b19f933e73"
      },
      "source": [
        "print(bddx_statements[12933])\n",
        "print(bddx_statements[35611])\n",
        "print(bddx_statements[101418])\n",
        "print(bddx_statements[35685])\n",
        "print(bddx_statements[50312])\n",
        "print(bddx_statements[8567])\n",
        "print(bddx_statements[30840])\n",
        "print(bddx_statements[37050])\n",
        "print(bddx_statements[71176])\n",
        "print(bddx_statements[35402])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The car drives forward because traffic is moving normal.\n",
            "The car drives forward because traffic in front of it is moving.\n",
            "The car is driving forward as its lane of traffic flows freely.\n",
            "The car drives down a street because traffic is moving and lights are green.\n",
            "The car proceeds down the highway as traffic ahead is flowing.\n",
            "The car is driving forward as traffic flows freely.\n",
            "The car is driving forward because traffic is traveling at a normal rate.\n",
            "The car is driving forward because traffic in front of it is moving at a normal rate.\n",
            "The car drives down the highway. because the road is clear and traffic is moving.\n",
            "The car drives forward because traffic in front of it is moving forward.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DIL7zPa8VJwq",
        "colab_type": "text"
      },
      "source": [
        "## Experiment 1: Doc2Vec Validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Plhq4FKSW1jh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# BDDX returned these three objects as the most similar to the sentence: The car is driving forward as traffic flows freely.\n",
        "# sdl objects 862,2374,6761\n",
        "doc_vec_A = one_hot_sdlEmbedding[12933].numpy()\n",
        "doc_vec_B = one_hot_sdlEmbedding[35611].numpy()\n",
        "doc_vec_C = one_hot_sdlEmbedding[101418].numpy()\n",
        "\n",
        "doc_vec_diff1 = one_hot_sdlEmbedding[61].numpy()\n",
        "reference = one_hot_sdlEmbedding[45].numpy()\n",
        "\n",
        "\n",
        "mseAB_doc_vec = (np.square(doc_vec_A - doc_vec_B)).mean(axis=None)\n",
        "mseBC_doc_vec = (np.square(doc_vec_B - doc_vec_C)).mean(axis=None)\n",
        "mseAC_doc_vec = (np.square(doc_vec_A - doc_vec_C)).mean(axis=None)\n",
        "\n",
        "mseDiffA_doc_vec = (np.square(doc_vec_A - doc_vec_diff1)).mean(axis=None)\n",
        "mseDiffB_doc_vec = (np.square(doc_vec_B - doc_vec_diff1)).mean(axis=None)\n",
        "mseDiffC_doc_vec = (np.square(doc_vec_C - doc_vec_diff1)).mean(axis=None)\n",
        "\n",
        "mseReferenceA_doc_vec = (np.square(doc_vec_A - reference)).mean(axis=None)\n",
        "mseReferenceB_doc_vec = (np.square(doc_vec_B - reference)).mean(axis=None)\n",
        "mseReferenceC_doc_vec = (np.square(doc_vec_C - reference)).mean(axis=None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5dZvNILnXr_L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "e0db610e-9b5b-4c9c-c1b5-3019fe78ffb5"
      },
      "source": [
        "print(\"MSE between SDL object 862 and 2374: \", mseAB_doc_vec)\n",
        "print(\"MSE between SDL object 2374 and 6761: \", mseBC_doc_vec)\n",
        "print(\"MSE between SDL object 862 and 6761: \", mseAC_doc_vec)\n",
        "\n",
        "print(\"MSE between SDL object 862 and diff: \", mseDiffA_doc_vec)\n",
        "print(\"MSE between SDL object 2374 and diff: \", mseDiffB_doc_vec)\n",
        "print(\"MSE between SDL object 6761 and diff: \", mseDiffC_doc_vec)\n",
        "\n",
        "print(\"MSE between SDL object 862 and reference: \", mseReferenceA_doc_vec)\n",
        "print(\"MSE between SDL object 2374 and reference: \", mseReferenceB_doc_vec)\n",
        "print(\"MSE between SDL object 6761 and reference: \", mseReferenceC_doc_vec)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MSE between SDL object 862 and 2374:  0.0\n",
            "MSE between SDL object 2374 and 6761:  0.0\n",
            "MSE between SDL object 862 and 6761:  0.0\n",
            "MSE between SDL object 862 and diff:  0.0009276437847866419\n",
            "MSE between SDL object 2374 and diff:  0.0009276437847866419\n",
            "MSE between SDL object 6761 and diff:  0.0009276437847866419\n",
            "MSE between SDL object 862 and reference:  0.0\n",
            "MSE between SDL object 2374 and reference:  0.0\n",
            "MSE between SDL object 6761 and reference:  0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Nq3LZcgXwas",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "85f4a437-9e2c-498b-8955-4daf4b4cbe2f"
      },
      "source": [
        "# corresponding SDL embeddings\n",
        "# time segment 4\n",
        "# time segment 2\n",
        "# time segment 4\n",
        "\n",
        "examples = [862,2374,6761] \n",
        "\n",
        "for example in examples:\n",
        "    print('Object %i: '%(example))\n",
        "    print(\"Actors: \")\n",
        "    print(sdlObjectList[example].statements)\n",
        "\n",
        "    for a in range(len(sdlObjectList[example].actors)):\n",
        "      actorsIndex = str(a+1)\n",
        "      for j in range(len(sdlObjectList[example].actors[actorsIndex])):\n",
        "        print('Time segment:', actorsIndex, \",  %s: %s\"%(sdlObjectList[example].actors[actorsIndex][j].description,sdlObjectList[example].actors[actorsIndex][j].action))\n",
        "    print('Scene: ', sdlObjectList[example].scene)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Object 862: \n",
            "Actors: \n",
            "{'1': 'The car is stopped because traffic in front of it is stopped.', '2': 'The car accelerates slowly as traffic in front of it starts to move.', '3': 'The car veers slightly left and back to get around a parked vehicle.', '4': 'The car drives forward because traffic is moving normal.', '5': 'No Data Recorded', '6': 'No Data Recorded', '7': 'No Data Recorded', '8': 'No Data Recorded', '9': 'No Data Recorded', '10': 'No Data Recorded', '11': 'No Data Recorded', '12': 'No Data Recorded', '13': 'No Data Recorded', '14': 'No Data Recorded', '15': 'No Data Recorded'}\n",
            "Time segment: 1 ,  ego: stop\n",
            "Time segment: 1 ,  traffic: stop\n",
            "Time segment: 2 ,  ego: accelerate\n",
            "Time segment: 2 ,  traffic: forward\n",
            "Time segment: 4 ,  ego: forward\n",
            "Time segment: 4 ,  traffic: forward\n",
            "Time segment: 5 ,  NaN: NaN\n",
            "Time segment: 6 ,  NaN: NaN\n",
            "Time segment: 7 ,  NaN: NaN\n",
            "Time segment: 8 ,  NaN: NaN\n",
            "Time segment: 9 ,  NaN: NaN\n",
            "Time segment: 10 ,  NaN: NaN\n",
            "Time segment: 11 ,  NaN: NaN\n",
            "Time segment: 12 ,  NaN: NaN\n",
            "Time segment: 13 ,  NaN: NaN\n",
            "Time segment: 14 ,  NaN: NaN\n",
            "Time segment: 15 ,  NaN: NaN\n",
            "Scene:  {'1': [], '2': [], '3': [], '4': [], '5': ['NaN'], '6': ['NaN'], '7': ['NaN'], '8': ['NaN'], '9': ['NaN'], '10': ['NaN'], '11': ['NaN'], '12': ['NaN'], '13': ['NaN'], '14': ['NaN'], '15': ['NaN']}\n",
            "Object 2374: \n",
            "Actors: \n",
            "{'1': 'The car stays to the left of its lane as it passes a parked car on its right.', '2': 'The car drives forward because traffic in front of it is moving.', '3': 'The car slows as it approaches stopped traffic at a red light.', '4': 'The car merges into the left lane due to that lane being free of traffic.', '5': 'The car slows to a stop due to the red light.', '6': 'The car is stopped because the light is red and there are pedestrians crossing the street.', '7': 'No Data Recorded', '8': 'No Data Recorded', '9': 'No Data Recorded', '10': 'No Data Recorded', '11': 'No Data Recorded', '12': 'No Data Recorded', '13': 'No Data Recorded', '14': 'No Data Recorded', '15': 'No Data Recorded'}\n",
            "Time segment: 1 ,  ego: forward\n",
            "Time segment: 1 ,  light vehicle: \n",
            "Time segment: 2 ,  ego: forward\n",
            "Time segment: 2 ,  traffic: forward\n",
            "Time segment: 3 ,  ego: brake\n",
            "Time segment: 3 ,  traffic: \n",
            "Time segment: 4 ,  ego: merge left\n",
            "Time segment: 5 ,  ego: brake\n",
            "Time segment: 6 ,  ego: stop\n",
            "Time segment: 6 ,  pedestrian: walk\n",
            "Time segment: 7 ,  NaN: NaN\n",
            "Time segment: 8 ,  NaN: NaN\n",
            "Time segment: 9 ,  NaN: NaN\n",
            "Time segment: 10 ,  NaN: NaN\n",
            "Time segment: 11 ,  NaN: NaN\n",
            "Time segment: 12 ,  NaN: NaN\n",
            "Time segment: 13 ,  NaN: NaN\n",
            "Time segment: 14 ,  NaN: NaN\n",
            "Time segment: 15 ,  NaN: NaN\n",
            "Scene:  {'1': [], '2': [], '3': ['light'], '4': [], '5': ['light'], '6': ['red light'], '7': ['NaN'], '8': ['NaN'], '9': ['NaN'], '10': ['NaN'], '11': ['NaN'], '12': ['NaN'], '13': ['NaN'], '14': ['NaN'], '15': ['NaN']}\n",
            "Object 6761: \n",
            "Actors: \n",
            "{'1': 'The car is driving forward because traffic in front of it is flowing normally.', '2': 'The car slows as traffic in front of it brakes.', '3': 'The car accelerates as traffic in front of it speeds up.', '4': 'The car is driving forward as its lane of traffic flows freely.', '5': 'No Data Recorded', '6': 'No Data Recorded', '7': 'No Data Recorded', '8': 'No Data Recorded', '9': 'No Data Recorded', '10': 'No Data Recorded', '11': 'No Data Recorded', '12': 'No Data Recorded', '13': 'No Data Recorded', '14': 'No Data Recorded', '15': 'No Data Recorded'}\n",
            "Time segment: 1 ,  ego: forward\n",
            "Time segment: 1 ,  traffic: forward\n",
            "Time segment: 2 ,  ego: brake\n",
            "Time segment: 2 ,  traffic: brake\n",
            "Time segment: 3 ,  ego: accelerate\n",
            "Time segment: 3 ,  traffic: accelerate\n",
            "Time segment: 4 ,  ego: forward\n",
            "Time segment: 4 ,  traffic: forward\n",
            "Time segment: 5 ,  NaN: NaN\n",
            "Time segment: 6 ,  NaN: NaN\n",
            "Time segment: 7 ,  NaN: NaN\n",
            "Time segment: 8 ,  NaN: NaN\n",
            "Time segment: 9 ,  NaN: NaN\n",
            "Time segment: 10 ,  NaN: NaN\n",
            "Time segment: 11 ,  NaN: NaN\n",
            "Time segment: 12 ,  NaN: NaN\n",
            "Time segment: 13 ,  NaN: NaN\n",
            "Time segment: 14 ,  NaN: NaN\n",
            "Time segment: 15 ,  NaN: NaN\n",
            "Scene:  {'1': [], '2': [], '3': [], '4': [], '5': ['NaN'], '6': ['NaN'], '7': ['NaN'], '8': ['NaN'], '9': ['NaN'], '10': ['NaN'], '11': ['NaN'], '12': ['NaN'], '13': ['NaN'], '14': ['NaN'], '15': ['NaN']}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SLyarepVDINV",
        "colab_type": "text"
      },
      "source": [
        "# Experiment 2: SDL Validation by Visual Inspection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PpLS8IxGC-VA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1c5af3b7-4aa1-47cf-9539-821542c10bd4"
      },
      "source": [
        "# sdl 4: one_hot_sdlEmbedding[60] = one_hot_sdlEmbedding[(15*4)] ----> 15 time segments per sdl + 1st time segment in sdl object 4\n",
        "# sdl 32: one_hot_sdlEmbedding[480] = one_hot_sdlEmbedding[(15*32)]----> 15 time segments per sdl + 1st time segment in sdl object 32\n",
        "# sdl 34: one_hot_sdlEmbedding[510] = one_hot_sdlEmbedding[(15*34)]----> 15 time segments per sdl + 1st time segment in sdl object 34\n",
        "examples = [4,32,34] \n",
        "\n",
        "for example in examples:\n",
        "    print('Object %i: '%(example))\n",
        "    print(\"Actors: \")\n",
        "    print(sdlObjectList[example].statements)\n",
        "\n",
        "    for a in range(len(sdlObjectList[example].actors)):\n",
        "      actorsIndex = str(a+1)\n",
        "      for j in range(len(sdlObjectList[example].actors[actorsIndex])):\n",
        "        print('Time segment:', actorsIndex, \",  %s: %s\"%(sdlObjectList[example].actors[actorsIndex][j].description,sdlObjectList[example].actors[actorsIndex][j].action))\n",
        "    print('Scene: ', sdlObjectList[example].scene)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Object 4: \n",
            "Actors: \n",
            "{'1': 'The car is stopped because the light is red.', '2': 'The car is accelerating as the light turned green.', '3': 'The car is slowing because traffic in front of it is stopped.', '4': 'The car is driving forward slowly due to slow traffic in front of it.', '5': 'The car is merging into the left lane to make a left turn.', '6': 'No Data Recorded', '7': 'No Data Recorded', '8': 'No Data Recorded', '9': 'No Data Recorded', '10': 'No Data Recorded', '11': 'No Data Recorded', '12': 'No Data Recorded', '13': 'No Data Recorded', '14': 'No Data Recorded', '15': 'No Data Recorded'}\n",
            "Time segment: 1 ,  ego: stop\n",
            "Time segment: 2 ,  ego: accelerate\n",
            "Time segment: 3 ,  ego: brake\n",
            "Time segment: 3 ,  traffic: stop\n",
            "Time segment: 4 ,  ego: forward\n",
            "Time segment: 4 ,  traffic: \n",
            "Time segment: 5 ,  ego: merge left\n",
            "Time segment: 6 ,  NaN: NaN\n",
            "Time segment: 7 ,  NaN: NaN\n",
            "Time segment: 8 ,  NaN: NaN\n",
            "Time segment: 9 ,  NaN: NaN\n",
            "Time segment: 10 ,  NaN: NaN\n",
            "Time segment: 11 ,  NaN: NaN\n",
            "Time segment: 12 ,  NaN: NaN\n",
            "Time segment: 13 ,  NaN: NaN\n",
            "Time segment: 14 ,  NaN: NaN\n",
            "Time segment: 15 ,  NaN: NaN\n",
            "Scene:  {'1': ['red light'], '2': ['green light'], '3': [], '4': [], '5': [], '6': ['NaN'], '7': ['NaN'], '8': ['NaN'], '9': ['NaN'], '10': ['NaN'], '11': ['NaN'], '12': ['NaN'], '13': ['NaN'], '14': ['NaN'], '15': ['NaN']}\n",
            "Object 32: \n",
            "Actors: \n",
            "{'1': 'The car is stopped because the light is red.', '2': 'No Data Recorded', '3': 'No Data Recorded', '4': 'No Data Recorded', '5': 'No Data Recorded', '6': 'No Data Recorded', '7': 'No Data Recorded', '8': 'No Data Recorded', '9': 'No Data Recorded', '10': 'No Data Recorded', '11': 'No Data Recorded', '12': 'No Data Recorded', '13': 'No Data Recorded', '14': 'No Data Recorded', '15': 'No Data Recorded'}\n",
            "Time segment: 1 ,  ego: stop\n",
            "Time segment: 2 ,  NaN: NaN\n",
            "Time segment: 3 ,  NaN: NaN\n",
            "Time segment: 4 ,  NaN: NaN\n",
            "Time segment: 5 ,  NaN: NaN\n",
            "Time segment: 6 ,  NaN: NaN\n",
            "Time segment: 7 ,  NaN: NaN\n",
            "Time segment: 8 ,  NaN: NaN\n",
            "Time segment: 9 ,  NaN: NaN\n",
            "Time segment: 10 ,  NaN: NaN\n",
            "Time segment: 11 ,  NaN: NaN\n",
            "Time segment: 12 ,  NaN: NaN\n",
            "Time segment: 13 ,  NaN: NaN\n",
            "Time segment: 14 ,  NaN: NaN\n",
            "Time segment: 15 ,  NaN: NaN\n",
            "Scene:  {'1': ['red light'], '2': ['NaN'], '3': ['NaN'], '4': ['NaN'], '5': ['NaN'], '6': ['NaN'], '7': ['NaN'], '8': ['NaN'], '9': ['NaN'], '10': ['NaN'], '11': ['NaN'], '12': ['NaN'], '13': ['NaN'], '14': ['NaN'], '15': ['NaN']}\n",
            "Object 34: \n",
            "Actors: \n",
            "{'1': 'The car is stopped because the light is red.', '2': 'The car begins to creep forward because the light is green but there is traffic in the intersection', '3': 'No Data Recorded', '4': 'No Data Recorded', '5': 'No Data Recorded', '6': 'No Data Recorded', '7': 'No Data Recorded', '8': 'No Data Recorded', '9': 'No Data Recorded', '10': 'No Data Recorded', '11': 'No Data Recorded', '12': 'No Data Recorded', '13': 'No Data Recorded', '14': 'No Data Recorded', '15': 'No Data Recorded'}\n",
            "Time segment: 1 ,  ego: stop\n",
            "Time segment: 2 ,  ego: \n",
            "Time segment: 2 ,  traffic: \n",
            "Time segment: 3 ,  NaN: NaN\n",
            "Time segment: 4 ,  NaN: NaN\n",
            "Time segment: 5 ,  NaN: NaN\n",
            "Time segment: 6 ,  NaN: NaN\n",
            "Time segment: 7 ,  NaN: NaN\n",
            "Time segment: 8 ,  NaN: NaN\n",
            "Time segment: 9 ,  NaN: NaN\n",
            "Time segment: 10 ,  NaN: NaN\n",
            "Time segment: 11 ,  NaN: NaN\n",
            "Time segment: 12 ,  NaN: NaN\n",
            "Time segment: 13 ,  NaN: NaN\n",
            "Time segment: 14 ,  NaN: NaN\n",
            "Time segment: 15 ,  NaN: NaN\n",
            "Scene:  {'1': ['red light'], '2': ['green light'], '3': ['NaN'], '4': ['NaN'], '5': ['NaN'], '6': ['NaN'], '7': ['NaN'], '8': ['NaN'], '9': ['NaN'], '10': ['NaN'], '11': ['NaN'], '12': ['NaN'], '13': ['NaN'], '14': ['NaN'], '15': ['NaN']}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fLXTN7LtEQll",
        "colab_type": "text"
      },
      "source": [
        "## Experiment 2: MSE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xUgX1WVkizJV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "86d4da76-e8ff-4415-a53c-0d1f7e66bb09"
      },
      "source": [
        "print(bddx_statements[60])\n",
        "print(bddx_statements[480])\n",
        "print(bddx_statements[510])\n",
        "print(\"different: \", bddx_statements[45])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The car is stopped because the light is red.\n",
            "The car is stopped because the light is red.\n",
            "The car is stopped because the light is red.\n",
            "different:  The car is driving forward as traffic flows freely.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ieN02cR7G5Pv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "D = one_hot_sdlEmbedding[60].numpy()\n",
        "E = one_hot_sdlEmbedding[480].numpy()\n",
        "F = one_hot_sdlEmbedding[510].numpy()\n",
        "\n",
        "diff2 = one_hot_sdlEmbedding[45].numpy()\n",
        "\n",
        "mseDE = (np.square(D - E)).mean(axis=None)\n",
        "mseEF = (np.square(E - F)).mean(axis=None)\n",
        "mseDF = (np.square(D - F)).mean(axis=None)\n",
        "\n",
        "mseDiffD = (np.square(D - diff2)).mean(axis=None)\n",
        "mseDiffE = (np.square(E - diff2)).mean(axis=None)\n",
        "mseDiffF = (np.square(F - diff2)).mean(axis=None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-KXWHVsHG8R5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "7cd32aca-bec0-4893-d36b-da4076ec9df6"
      },
      "source": [
        "print(\"MSE between SDL object 4 and 32: \", mseDE)\n",
        "print(\"MSE between SDL object 32 and 34: \", mseEF)\n",
        "print(\"MSE between SDL object 4 and 34: \", mseDF)\n",
        "\n",
        "print(\"MSE between SDL object 4 and diff: \", mseDiffD)\n",
        "print(\"MSE between SDL object 32 and diff: \", mseDiffE)\n",
        "print(\"MSE between SDL object 34 and diff: \", mseDiffF)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MSE between SDL object 4 and 32:  0.0\n",
            "MSE between SDL object 32 and 34:  0.0\n",
            "MSE between SDL object 4 and 34:  0.0\n",
            "MSE between SDL object 4 and diff:  0.0009276437847866419\n",
            "MSE between SDL object 32 and diff:  0.0009276437847866419\n",
            "MSE between SDL object 34 and diff:  0.0009276437847866419\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C_E9wHoPETiB",
        "colab_type": "text"
      },
      "source": [
        "## Experiment 2: Doc2Vec Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZXR_aXdoFhaV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "4701f60e-207e-44e9-c595-493b321c69c4"
      },
      "source": [
        "# finds top 10 most similar sentences to test data \n",
        "test = \"The car is stopped because the light is red.\".split(\" \")  \n",
        "\n",
        "ivec = model.infer_vector(doc_words=test, steps=150, alpha=0.00025)\n",
        "model.docvecs.most_similar(positive=[ivec], topn=10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TZq27waiUM7c",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "ff78e406-c6c5-4c01-a629-7cff043c9a64"
      },
      "source": [
        "print(bddx_statements[8673])\n",
        "print(bddx_statements[104430])\n",
        "print(bddx_statements[3138])\n",
        "print(bddx_statements[1397])\n",
        "print(bddx_statements[47820])\n",
        "print(bddx_statements[48226])\n",
        "print(bddx_statements[902])\n",
        "print(bddx_statements[6859])\n",
        "print(bddx_statements[6904])\n",
        "print(bddx_statements[13545])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The car is stopped because the light is red.\n",
            "The car is stopped because the light is red.\n",
            "The car is stopped because the light is red.\n",
            "The car is stopped because the light is red.\n",
            "The is stopped because the light is red.\n",
            "The car is stopped. because the light is red.\n",
            "The car is stopped because the light is red.\n",
            "The car is stopped because the light is red.\n",
            "The car is stopped because the light is red.\n",
            "The car is stopped because the light is red.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2G6AQ82DjCQ4",
        "colab_type": "text"
      },
      "source": [
        "## Experiment 2: Doc2Vec Validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yYYpGIETjZ2s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# BDDX returned these three objects as the most similar to the sentence: The car is driving forward as traffic flows freely.\n",
        "# sdl objects 862,2374,6761\n",
        "doc_vec_D = one_hot_sdlEmbedding[8673].numpy()\n",
        "doc_vec_E = one_hot_sdlEmbedding[104430].numpy()\n",
        "doc_vec_F = one_hot_sdlEmbedding[3138].numpy()\n",
        "\n",
        "doc_vec_diff2 = one_hot_sdlEmbedding[45].numpy()\n",
        "reference = one_hot_sdlEmbedding[60].numpy()\n",
        "\n",
        "\n",
        "mseDE_doc_vec = (np.square(doc_vec_D - doc_vec_E)).mean(axis=None)\n",
        "mseEF_doc_vec = (np.square(doc_vec_E - doc_vec_F)).mean(axis=None)\n",
        "mseDF_doc_vec = (np.square(doc_vec_D - doc_vec_F)).mean(axis=None)\n",
        "\n",
        "mseDiffD_doc_vec = (np.square(doc_vec_D - doc_vec_diff2)).mean(axis=None)\n",
        "mseDiffE_doc_vec = (np.square(doc_vec_E - doc_vec_diff2)).mean(axis=None)\n",
        "mseDiffF_doc_vec = (np.square(doc_vec_F - doc_vec_diff2)).mean(axis=None)\n",
        "\n",
        "mseReferenceD_doc_vec = (np.square(doc_vec_D - reference)).mean(axis=None)\n",
        "mseReferenceE_doc_vec = (np.square(doc_vec_E - reference)).mean(axis=None)\n",
        "mseReferenceF_doc_vec = (np.square(doc_vec_F - reference)).mean(axis=None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j_qJ-o_ajdpk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "55b6051f-5dad-469e-c37d-f88e44a35f30"
      },
      "source": [
        "print(\"MSE between SDL object 8673 and 104430: \", mseDE_doc_vec)\n",
        "print(\"MSE between SDL object 104430 and 3138: \", mseEF_doc_vec)\n",
        "print(\"MSE between SDL object 8673 and 3138: \", mseDF_doc_vec)\n",
        "\n",
        "print(\"MSE between SDL object 8673 and diff: \", mseDiffD_doc_vec)\n",
        "print(\"MSE between SDL object 104430 and diff: \", mseDiffE_doc_vec)\n",
        "print(\"MSE between SDL object 3138 and diff: \", mseDiffF_doc_vec)\n",
        "\n",
        "print(\"MSE between SDL object 8673 and reference: \", mseReferenceD_doc_vec)\n",
        "print(\"MSE between SDL object 104430 and reference: \", mseReferenceE_doc_vec)\n",
        "print(\"MSE between SDL object 3138 and reference: \", mseReferenceF_doc_vec)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MSE between SDL object 8673 and 104430:  0.0\n",
            "MSE between SDL object 104430 and 3138:  0.0\n",
            "MSE between SDL object 8673 and 3138:  0.0\n",
            "MSE between SDL object 8673 and diff:  0.0009276437847866419\n",
            "MSE between SDL object 104430 and diff:  0.0009276437847866419\n",
            "MSE between SDL object 3138 and diff:  0.0009276437847866419\n",
            "MSE between SDL object 8673 and reference:  0.0\n",
            "MSE between SDL object 104430 and reference:  0.0\n",
            "MSE between SDL object 3138 and reference:  0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "porEe4_sjik5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8b5c2b71-3d6f-4f95-ba91-a7c1e3a3a52d"
      },
      "source": [
        "# corresponding SDL embeddings\n",
        "# time segment 4\n",
        "# time segment 1\n",
        "# time segment 4\n",
        "\n",
        "examples = [578,6962,209] \n",
        "\n",
        "for example in examples:\n",
        "    print('Object %i: '%(example))\n",
        "    print(\"Actors: \")\n",
        "    print(sdlObjectList[example].statements)\n",
        "\n",
        "    for a in range(len(sdlObjectList[example].actors)):\n",
        "      actorsIndex = str(a+1)\n",
        "      for j in range(len(sdlObjectList[example].actors[actorsIndex])):\n",
        "        print('Time segment:', actorsIndex, \",  %s: %s\"%(sdlObjectList[example].actors[actorsIndex][j].description,sdlObjectList[example].actors[actorsIndex][j].action))\n",
        "    print('Scene: ', sdlObjectList[example].scene)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Object 578: \n",
            "Actors: \n",
            "{'1': 'The car accelerates slowly to make a left turn.', '2': 'The car maintains speed because the road is clear.', '3': 'The car slows to a stop because the light is red.', '4': 'The car is stopped because the light is red.', '5': 'No Data Recorded', '6': 'No Data Recorded', '7': 'No Data Recorded', '8': 'No Data Recorded', '9': 'No Data Recorded', '10': 'No Data Recorded', '11': 'No Data Recorded', '12': 'No Data Recorded', '13': 'No Data Recorded', '14': 'No Data Recorded', '15': 'No Data Recorded'}\n",
            "Time segment: 1 ,  ego: accelerate\n",
            "Time segment: 3 ,  ego: brake\n",
            "Time segment: 4 ,  ego: stop\n",
            "Time segment: 5 ,  NaN: NaN\n",
            "Time segment: 6 ,  NaN: NaN\n",
            "Time segment: 7 ,  NaN: NaN\n",
            "Time segment: 8 ,  NaN: NaN\n",
            "Time segment: 9 ,  NaN: NaN\n",
            "Time segment: 10 ,  NaN: NaN\n",
            "Time segment: 11 ,  NaN: NaN\n",
            "Time segment: 12 ,  NaN: NaN\n",
            "Time segment: 13 ,  NaN: NaN\n",
            "Time segment: 14 ,  NaN: NaN\n",
            "Time segment: 15 ,  NaN: NaN\n",
            "Scene:  {'1': [], '2': [], '3': ['red light'], '4': ['red light'], '5': ['NaN'], '6': ['NaN'], '7': ['NaN'], '8': ['NaN'], '9': ['NaN'], '10': ['NaN'], '11': ['NaN'], '12': ['NaN'], '13': ['NaN'], '14': ['NaN'], '15': ['NaN']}\n",
            "Object 6962: \n",
            "Actors: \n",
            "{'1': 'The car is stopped because the light is red.', '2': 'No Data Recorded', '3': 'No Data Recorded', '4': 'No Data Recorded', '5': 'No Data Recorded', '6': 'No Data Recorded', '7': 'No Data Recorded', '8': 'No Data Recorded', '9': 'No Data Recorded', '10': 'No Data Recorded', '11': 'No Data Recorded', '12': 'No Data Recorded', '13': 'No Data Recorded', '14': 'No Data Recorded', '15': 'No Data Recorded'}\n",
            "Time segment: 1 ,  ego: stop\n",
            "Time segment: 2 ,  NaN: NaN\n",
            "Time segment: 3 ,  NaN: NaN\n",
            "Time segment: 4 ,  NaN: NaN\n",
            "Time segment: 5 ,  NaN: NaN\n",
            "Time segment: 6 ,  NaN: NaN\n",
            "Time segment: 7 ,  NaN: NaN\n",
            "Time segment: 8 ,  NaN: NaN\n",
            "Time segment: 9 ,  NaN: NaN\n",
            "Time segment: 10 ,  NaN: NaN\n",
            "Time segment: 11 ,  NaN: NaN\n",
            "Time segment: 12 ,  NaN: NaN\n",
            "Time segment: 13 ,  NaN: NaN\n",
            "Time segment: 14 ,  NaN: NaN\n",
            "Time segment: 15 ,  NaN: NaN\n",
            "Scene:  {'1': ['red light'], '2': ['NaN'], '3': ['NaN'], '4': ['NaN'], '5': ['NaN'], '6': ['NaN'], '7': ['NaN'], '8': ['NaN'], '9': ['NaN'], '10': ['NaN'], '11': ['NaN'], '12': ['NaN'], '13': ['NaN'], '14': ['NaN'], '15': ['NaN']}\n",
            "Object 209: \n",
            "Actors: \n",
            "{'1': 'The car maintains a constant speed and spacing with the vehicle ahead because traffic is moving smoothly.', '2': 'The car slows and veer right because there is a stop light and it wants in the far right turning lane.', '3': 'The car slows to a stop because traffic is stopped at a red light.', '4': 'The car is stopped because the light is red.', '5': 'The car begins to move forward as traffic moves forward.', '6': 'No Data Recorded', '7': 'No Data Recorded', '8': 'No Data Recorded', '9': 'No Data Recorded', '10': 'No Data Recorded', '11': 'No Data Recorded', '12': 'No Data Recorded', '13': 'No Data Recorded', '14': 'No Data Recorded', '15': 'No Data Recorded'}\n",
            "Time segment: 1 ,  ego: forward\n",
            "Time segment: 1 ,  traffic: forward\n",
            "Time segment: 2 ,  ego: brake\n",
            "Time segment: 3 ,  ego: brake\n",
            "Time segment: 3 ,  traffic: stop\n",
            "Time segment: 4 ,  ego: stop\n",
            "Time segment: 5 ,  ego: forward\n",
            "Time segment: 5 ,  traffic: forward\n",
            "Time segment: 6 ,  NaN: NaN\n",
            "Time segment: 7 ,  NaN: NaN\n",
            "Time segment: 8 ,  NaN: NaN\n",
            "Time segment: 9 ,  NaN: NaN\n",
            "Time segment: 10 ,  NaN: NaN\n",
            "Time segment: 11 ,  NaN: NaN\n",
            "Time segment: 12 ,  NaN: NaN\n",
            "Time segment: 13 ,  NaN: NaN\n",
            "Time segment: 14 ,  NaN: NaN\n",
            "Time segment: 15 ,  NaN: NaN\n",
            "Scene:  {'1': [], '2': ['light'], '3': ['light'], '4': ['red light'], '5': [], '6': ['NaN'], '7': ['NaN'], '8': ['NaN'], '9': ['NaN'], '10': ['NaN'], '11': ['NaN'], '12': ['NaN'], '13': ['NaN'], '14': ['NaN'], '15': ['NaN']}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IdXWtk95KPr-",
        "colab_type": "text"
      },
      "source": [
        "# Experiment 3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mo3fIbcXKchc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "f253b834-a873-4cd6-fc10-73a28ac48748"
      },
      "source": [
        "first_error = []\n",
        "second_error = []\n",
        "third_error = []\n",
        "fourth_error = []\n",
        "fifth_error = []\n",
        "for i,j in enumerate(one_hot_sdlEmbedding):\n",
        "    if (i != 6996):\n",
        "        test = sdlObjectList[i].statements['1'].split(\" \")  \n",
        "        ivec = model.infer_vector(doc_words=test, steps=150, alpha=0.00025)\n",
        "        similar_sdls = model.docvecs.most_similar(positive=[ivec], topn=10)\n",
        "        \n",
        "        first = one_hot_sdlEmbedding[int(similar_sdls[0][0])].numpy()\n",
        "        second = one_hot_sdlEmbedding[int(similar_sdls[1][0])].numpy()\n",
        "        third = one_hot_sdlEmbedding[int(similar_sdls[2][0])].numpy()\n",
        "        fourth = one_hot_sdlEmbedding[int(similar_sdls[3][0])].numpy()\n",
        "        fifth = one_hot_sdlEmbedding[int(similar_sdls[4][0])].numpy()\n",
        "        \n",
        "        first_error.append((np.square(j - first)).mean(axis=None))\n",
        "        second_error.append((np.square(j - second)).mean(axis=None))\n",
        "        third_error.append((np.square(j - third)).mean(axis=None))\n",
        "        fourth_error.append((np.square(j - fourth)).mean(axis=None))\n",
        "        fifth_error.append((np.square(j - fifth)).mean(axis=None))\n",
        "    else:\n",
        "        break\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u-yBpXegFRa6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "len(first_error)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sYu8bNC7ONTn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "count_first = len([i for i in first_error if i >= 0.0009276437847866419]) \n",
        "count_second = len([i for i in second_error if i >= 0.0009276437847866419]) \n",
        "count_third = len([i for i in third_error if i >= 0.0009276437847866419]) \n",
        "count_fourth = len([i for i in fourth_error if i >= 0.0009276437847866419]) \n",
        "count_fifth = len([i for i in fifth_error if i >= 0.0009276437847866419]) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JaU9KgOUPi1y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "c8c7282c-ddcc-427b-d9e7-1189dec44c7a"
      },
      "source": [
        "print(count_first)\n",
        "print(count_second)\n",
        "print(count_third)\n",
        "print(count_fourth)\n",
        "print(count_fifth)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2257\n",
            "2195\n",
            "2172\n",
            "2185\n",
            "2129\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}